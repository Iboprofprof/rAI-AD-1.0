{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EfficientAD â€“ Brain Tumor Anomaly Detection\n",
    "# Jupyter Notebook for Research & Publication\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# GPU Check\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device) \n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SimpleITK available - N4 Bias Correction enabled\n",
      "âœ… MRI Preprocessor loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MRI Preprocessing Pipeline - Complete Implementation\n",
    "# ============================================================\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for optional medical imaging libraries\n",
    "try:\n",
    "    import SimpleITK as sitk\n",
    "    SITK_AVAILABLE = True\n",
    "    print(\"âœ“ SimpleITK available - N4 Bias Correction enabled\")\n",
    "except ImportError:\n",
    "    SITK_AVAILABLE = False\n",
    "    print(\"âš  SimpleITK not available - Install with: pip install SimpleITK\")\n",
    "\n",
    "\n",
    "class MRIPreprocessor:\n",
    "    \"\"\"Medical-grade MRI preprocessing for anomaly detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dir, output_dir, target_size=(256, 256),\n",
    "                 normalization_method='minmax', random_seed=42):\n",
    "        self.input_dir = Path(input_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.target_size = target_size\n",
    "        self.normalization_method = normalization_method\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        self.stats = {\n",
    "            'loaded': 0, 'dropped_empty': 0, 'dropped_artifact': 0,\n",
    "            'augmented': 0, 'healthy_train': 0, 'healthy_test': 0, 'tumor_test': 0\n",
    "        }\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # ============================================================\n",
    "    # LOADING\n",
    "    # ============================================================\n",
    "    def load_images(self, folder, label):\n",
    "        \"\"\"Load all images from folder with metadata.\"\"\"\n",
    "        images = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "            image_paths.extend(list(folder.glob(ext)))\n",
    "        \n",
    "        for img_path in tqdm(image_paths, desc=f\"Loading {label}\"):\n",
    "            try:\n",
    "                img = Image.open(img_path)  # no grayscale conversion\n",
    "                img_array = np.array(img, dtype=np.float32)\n",
    "                \n",
    "                images.append({\n",
    "                    'data': img_array,\n",
    "                    'metadata': {'path': str(img_path), 'label': label}\n",
    "                })\n",
    "                self.stats['loaded'] += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {img_path}: {e}\")\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    # ============================================================\n",
    "    # NORMALIZATION\n",
    "    # ============================================================\n",
    "    def normalize_zscore(self, img):\n",
    "        \"\"\"Z-Score: (img - mean) / std (no-op ablation)\"\"\"\n",
    "        return img\n",
    "    \n",
    "    def normalize_minmax(self, img):\n",
    "        \"\"\"Min-Max: (img - min) / (max - min) (no-op ablation)\"\"\"\n",
    "        return img\n",
    "    \n",
    "    def normalize_intensity(self, img):\n",
    "        \"\"\"Apply selected normalization (no-op ablation).\"\"\"\n",
    "        return img\n",
    "    \n",
    "    # ============================================================\n",
    "    # CLAHE\n",
    "    # ============================================================\n",
    "    def apply_clahe(self, img, clip_limit=2.0, tile_size=8):\n",
    "        \"\"\"CLAHE (no-op ablation).\"\"\"\n",
    "        return img\n",
    "    \n",
    "    # ============================================================\n",
    "    # SPATIAL NORMALIZATION\n",
    "    # ============================================================\n",
    "    def resize_image(self, img, keep_aspect_ratio=True):\n",
    "        \"\"\"Resize (no-op ablation).\"\"\"\n",
    "        return img\n",
    "    \n",
    "    # ============================================================\n",
    "    # DATA CLEANING\n",
    "    # ============================================================\n",
    "    def is_empty_slice(self, img, threshold=0.05):\n",
    "        \"\"\"Check if image is mostly empty.\"\"\"\n",
    "        return np.count_nonzero(img) / img.size < threshold\n",
    "    \n",
    "    def is_artifact(self, img, std_threshold=0.01):\n",
    "        \"\"\"Detect artifacts via low std.\"\"\"\n",
    "        return img.std() < std_threshold\n",
    "    \n",
    "    def clean_image(self, img):\n",
    "        \"\"\"Filter bad images. Return None if should be dropped.\"\"\"\n",
    "        if self.is_empty_slice(img, 0.05):\n",
    "            self.stats['dropped_empty'] += 1\n",
    "            return None\n",
    "        if self.is_artifact(img, 0.01):\n",
    "            self.stats['dropped_artifact'] += 1\n",
    "            return None\n",
    "        return img\n",
    "    \n",
    "    # ============================================================\n",
    "    # AUGMENTATION\n",
    "    # ============================================================\n",
    "    def augment_image(self, img, num_augmentations=2):\n",
    "        \"\"\"Apply augmentations: rotation, flip, noise, jitter.\"\"\"\n",
    "        augmented = []\n",
    "        \n",
    "        for _ in range(num_augmentations):\n",
    "            aug_img = img.copy()\n",
    "            \n",
    "            # Random rotation Â±10Â°\n",
    "            if np.random.rand() > 0.5:\n",
    "                angle = np.random.uniform(-10, 10)\n",
    "                h, w = aug_img.shape[:2]\n",
    "                M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "                aug_img = cv2.warpAffine(aug_img, M, (w, h), borderValue=0)\n",
    "            \n",
    "            # Random horizontal flip\n",
    "            if np.random.rand() > 0.5:\n",
    "                aug_img = cv2.flip(aug_img, 1)\n",
    "            \n",
    "            # Random Gaussian noise\n",
    "            if np.random.rand() > 0.5:\n",
    "                noise = np.random.normal(0, 0.02, aug_img.shape)\n",
    "                aug_img = np.clip(aug_img + noise, 0, 255)\n",
    "            \n",
    "            # Random intensity jitter\n",
    "            if np.random.rand() > 0.5:\n",
    "                jitter = np.random.uniform(0.9, 1.1)\n",
    "                aug_img = np.clip(aug_img * jitter, 0, 255)\n",
    "            \n",
    "            augmented.append(aug_img.astype(np.float32))\n",
    "            self.stats['augmented'] += 1\n",
    "        \n",
    "        return augmented\n",
    "    \n",
    "    # ============================================================\n",
    "    # SAVING\n",
    "    # ============================================================\n",
    "    def save_image(self, img, output_path):\n",
    "        \"\"\"Save image without normalization or forced grayscale.\"\"\"\n",
    "        img_uint8 = np.clip(img, 0, 255).astype(np.uint8)\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        Image.fromarray(img_uint8).save(output_path)\n",
    "    \n",
    "    # ============================================================\n",
    "    # FULL PIPELINE\n",
    "    # ============================================================\n",
    "    def preprocess_dataset(self, train_test_split_ratio=0.8, augment_train=True, target_test_samples=5000):\n",
    "        \"\"\"Execute complete preprocessing pipeline.\n",
    "        \n",
    "        Args:\n",
    "            train_test_split_ratio: Initial split ratio (will be adjusted to meet target_test_samples)\n",
    "            augment_train: Apply augmentation to training set\n",
    "            target_test_samples: Target number of healthy test samples (default: 5000)\n",
    "        \"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"ðŸ§  MRI Preprocessing Pipeline\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ðŸŽ¯ Target healthy test samples: {target_test_samples}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load healthy images\n",
    "        healthy_folder = self.input_dir / 'no_tumor'\n",
    "        if not healthy_folder.exists():\n",
    "            raise FileNotFoundError(f\"Healthy folder not found: {healthy_folder}\")\n",
    "        \n",
    "        healthy_images = self.load_images(healthy_folder, 'no_tumor')\n",
    "        print(f\"âœ“ Loaded {len(healthy_images)} healthy images\")\n",
    "        \n",
    "        # Load tumor images\n",
    "        tumor_images = []\n",
    "        for tumor_type in ['glioma', 'meningioma', 'pituitary']:\n",
    "            tumor_folder = self.input_dir / tumor_type\n",
    "            if tumor_folder.exists():\n",
    "                images = self.load_images(tumor_folder, tumor_type)\n",
    "                tumor_images.extend(images)\n",
    "        \n",
    "        print(f\"âœ“ Loaded {len(tumor_images)} tumor images\")\n",
    "        \n",
    "        # Preprocess healthy\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Processing Healthy Images\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        healthy_processed = []\n",
    "        for item in tqdm(healthy_images, desc=\"Processing healthy\"):\n",
    "            img = item['data']\n",
    "            img = self.normalize_intensity(img)\n",
    "            img = self.apply_clahe(img)\n",
    "            img = self.resize_image(img, keep_aspect_ratio=True)\n",
    "            img = self.clean_image(img)\n",
    "            \n",
    "            if img is not None:\n",
    "                healthy_processed.append({'data': img, 'metadata': item['metadata']})\n",
    "        \n",
    "        print(f\"âœ“ {len(healthy_processed)} healthy images after cleaning\")\n",
    "        \n",
    "        # Calculate augmentation needed to reach target test samples\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Calculating Augmentation Strategy\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        current_count = len(healthy_processed)\n",
    "        \n",
    "        # If we need more samples, apply augmentation BEFORE splitting\n",
    "        if current_count < target_test_samples * 1.25:  # Need 125% of target (80/20 split)\n",
    "            print(f\"âš ï¸  Only {current_count} healthy images available\")\n",
    "            print(f\"ðŸ”„ Applying pre-split augmentation to reach {target_test_samples} test samples\")\n",
    "            \n",
    "            # Calculate how many augmentations needed per image\n",
    "            required_total = int(target_test_samples * 1.25)  # Total needed for 80/20 split\n",
    "            augmentations_per_image = max(1, (required_total // current_count))\n",
    "            \n",
    "            print(f\"   Strategy: {augmentations_per_image} augmentations per image\")\n",
    "            \n",
    "            healthy_augmented = []\n",
    "            for item in tqdm(healthy_processed, desc=\"Pre-split augmentation\"):\n",
    "                # Keep original\n",
    "                healthy_augmented.append(item)\n",
    "                # Add augmentations\n",
    "                aug_imgs = self.augment_image(item['data'], num_augmentations=augmentations_per_image)\n",
    "                for aug_img in aug_imgs:\n",
    "                    healthy_augmented.append({\n",
    "                        'data': aug_img,\n",
    "                        'metadata': {**item['metadata'], 'augmented': True}\n",
    "                    })\n",
    "            \n",
    "            healthy_processed = healthy_augmented\n",
    "            print(f\"âœ“ {len(healthy_processed)} images after pre-split augmentation\")\n",
    "        \n",
    "        # Split healthy into train/test\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Splitting Healthy Images\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Adjust split ratio to get close to target_test_samples\n",
    "        if len(healthy_processed) > target_test_samples:\n",
    "            adjusted_ratio = 1 - (target_test_samples / len(healthy_processed))\n",
    "            adjusted_ratio = max(0.5, min(0.9, adjusted_ratio))  # Keep between 50-90%\n",
    "            print(f\"   Adjusting split ratio to {adjusted_ratio:.2f} to reach target test samples\")\n",
    "        else:\n",
    "            adjusted_ratio = train_test_split_ratio\n",
    "        \n",
    "        n_train = int(len(healthy_processed) * adjusted_ratio)\n",
    "        indices = np.random.permutation(len(healthy_processed))\n",
    "        \n",
    "        healthy_train = [healthy_processed[i] for i in indices[:n_train]]\n",
    "        healthy_test = [healthy_processed[i] for i in indices[n_train:]]\n",
    "        \n",
    "        print(f\"âœ“ Train: {len(healthy_train)}, Test: {len(healthy_test)}\")\n",
    "        \n",
    "        if len(healthy_test) < target_test_samples:\n",
    "            print(f\"âš ï¸  Warning: Only {len(healthy_test)} test samples (target: {target_test_samples})\")\n",
    "            print(f\"   Add more images to dataset_raw/no_tumor/ for better results\")\n",
    "        \n",
    "        # Augment healthy train\n",
    "        if augment_train:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"Augmenting Healthy Train\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            augmented_train = []\n",
    "            for item in tqdm(healthy_train, desc=\"Augmenting\"):\n",
    "                augmented_train.append(item)\n",
    "                aug_imgs = self.augment_image(item['data'], num_augmentations=2)\n",
    "                for aug_img in aug_imgs:\n",
    "                    augmented_train.append({\n",
    "                        'data': aug_img,\n",
    "                        'metadata': {**item['metadata'], 'augmented': True}\n",
    "                    })\n",
    "            \n",
    "            healthy_train = augmented_train\n",
    "            print(f\"âœ“ {len(healthy_train)} images after augmentation\")\n",
    "        \n",
    "        # Preprocess tumor (NO augmentation)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Processing Tumor Images\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        tumor_processed = []\n",
    "        for item in tqdm(tumor_images, desc=\"Processing tumor\"):\n",
    "            img = item['data']\n",
    "            img = self.normalize_intensity(img)\n",
    "            img = self.apply_clahe(img)\n",
    "            img = self.resize_image(img, keep_aspect_ratio=True)\n",
    "            img = self.clean_image(img)\n",
    "            \n",
    "            if img is not None:\n",
    "                tumor_processed.append({'data': img, 'metadata': item['metadata']})\n",
    "        \n",
    "        print(f\"âœ“ {len(tumor_processed)} tumor images after cleaning\")\n",
    "        \n",
    "        # Save to output structure\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Saving Preprocessed Dataset\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        output_structure = {\n",
    "            'train/healthy': healthy_train,\n",
    "            'test/healthy': healthy_test,\n",
    "            'test/tumor': tumor_processed\n",
    "        }\n",
    "        \n",
    "        for folder_name, images in output_structure.items():\n",
    "            output_folder = self.output_dir / folder_name\n",
    "            output_folder.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for idx, item in enumerate(tqdm(images, desc=f\"Saving {folder_name}\")):\n",
    "                img = item['data']\n",
    "                original_name = Path(item['metadata']['path']).stem\n",
    "                output_path = output_folder / f\"{original_name}_{idx:05d}.png\"\n",
    "                self.save_image(img, output_path)\n",
    "            \n",
    "            # Update statistics\n",
    "            if 'train' in folder_name:\n",
    "                self.stats['healthy_train'] = len(images)\n",
    "            elif 'healthy' in folder_name:\n",
    "                self.stats['healthy_test'] = len(images)\n",
    "            else:\n",
    "                self.stats['tumor_test'] = len(images)\n",
    "        \n",
    "        # Save statistics\n",
    "        stats_path = self.output_dir / 'preprocessing_stats.json'\n",
    "        with open(stats_path, 'w') as f:\n",
    "            json.dump(self.stats, f, indent=2)\n",
    "        \n",
    "        # Print summary\n",
    "        self.print_summary()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Print preprocessing summary.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ“Š PREPROCESSING SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Healthy train:        {self.stats['healthy_train']}\")\n",
    "        print(f\"Healthy test:         {self.stats['healthy_test']}\")\n",
    "        print(f\"Tumor test:           {self.stats['tumor_test']}\")\n",
    "        print(f\"Dropped (empty):      {self.stats['dropped_empty']}\")\n",
    "        print(f\"Dropped (artifact):   {self.stats['dropped_artifact']}\")\n",
    "        print(f\"Augmented:            {self.stats['augmented']}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"âœ… Dataset ready for EfficientAD training\")\n",
    "        print(f\"ðŸ“ Output: {self.output_dir}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "\n",
    "print(\"âœ… MRI Preprocessor loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8433c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ§  MRI Preprocessing Pipeline\n",
      "============================================================\n",
      "ðŸŽ¯ Target healthy test samples: 5000\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading no_tumor: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1757/1757 [00:19<00:00, 89.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 1757 healthy images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading glioma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3754/3754 [00:59<00:00, 63.17it/s]\n",
      "Loading meningioma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2343/2343 [00:40<00:00, 58.56it/s]\n",
      "Loading pituitary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2706/2706 [01:03<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 8803 tumor images\n",
      "\n",
      "============================================================\n",
      "Processing Healthy Images\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing healthy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1757/1757 [00:17<00:00, 101.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ 1757 healthy images after cleaning\n",
      "\n",
      "============================================================\n",
      "Calculating Augmentation Strategy\n",
      "============================================================\n",
      "âš ï¸  Only 1757 healthy images available\n",
      "ðŸ”„ Applying pre-split augmentation to reach 5000 test samples\n",
      "   Strategy: 3 augmentations per image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-split augmentation:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1363/1757 [00:38<00:11, 33.27it/s]"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Run Preprocessing Pipeline\n",
    "# ============================================================\n",
    "\n",
    "# Configuration\n",
    "INPUT_DIR = r\"dataset_raw\" # Pfad zu dataset_raw\n",
    "OUTPUT_DIR = r\"dataset_preprocessed\" # Pfad zu dataset_preprocessed (dafÃ¼r brauchst du kein Ordner, der erstellt selbst einen)\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = MRIPreprocessor(\n",
    "    input_dir=INPUT_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    target_size=(256, 256),\n",
    "    normalization_method='minmax',  # Options: 'zscore', 'minmax', 'combined'\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# Run preprocessing\n",
    "preprocessor.preprocess_dataset(\n",
    "    train_test_split_ratio=0.8,\n",
    "    augment_train=True,\n",
    "    target_test_samples=5000  # ðŸŽ¯ Ziel: 5.000 healthy Test-Bilder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c28b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking for dataset folders...\n",
      "\n",
      "ðŸ“ Raw data (dataset_raw/):\n",
      "   âœ“ dataset_raw/no_tumor: 1753 images\n",
      "   âœ“ dataset_raw/glioma: 3754 images\n",
      "   âœ“ dataset_raw/meningioma: 2343 images\n",
      "   âœ“ dataset_raw/pituitary: 2706 images\n",
      "\n",
      "ðŸ“ Preprocessed data (dataset/):\n",
      "   âœ“ dataset/train/healthy: 10542 images\n",
      "   âœ“ dataset/test/healthy: 3514 images\n",
      "   âœ“ dataset/test/tumor: 8803 images\n",
      "\n",
      "============================================================\n",
      "ðŸ’¡ Next steps:\n",
      "============================================================\n",
      "âœ… Dataset is ready! You can proceed with training.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Check Dataset Structure\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(r\"dataset_raw\") #Pfad zu dataset_raw\n",
    "\n",
    "print(\"ðŸ” Checking for dataset folders...\")\n",
    "print(\"\\nðŸ“ Raw data (dataset_raw/):\")\n",
    "for folder in ['dataset_raw/no_tumor', 'dataset_raw/glioma', 'dataset_raw/meningioma', 'dataset_raw/pituitary']:\n",
    "    path = base_path / folder\n",
    "    if path.exists():\n",
    "        count = len(list(path.glob('*.jpg'))) + len(list(path.glob('*.png')))\n",
    "        print(f\"   âœ“ {folder}: {count} images\")\n",
    "    else:\n",
    "        print(f\"   âœ— {folder}: NOT FOUND\")\n",
    "\n",
    "print(\"\\nðŸ“ Preprocessed data (dataset/):\")\n",
    "for folder in ['dataset/train/healthy', 'dataset/test/healthy', 'dataset/test/tumor']:\n",
    "    path = base_path / folder\n",
    "    if path.exists():\n",
    "        count = len(list(path.glob('*.jpg'))) + len(list(path.glob('*.png')))\n",
    "        print(f\"   âœ“ {folder}: {count} images\")\n",
    "    else:\n",
    "        print(f\"   âœ— {folder}: NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ’¡ Next steps:\")\n",
    "print(\"=\"*60)\n",
    "if not (base_path / 'dataset_raw/no_tumor').exists():\n",
    "    print(\"1. Create dataset_raw/ folder structure\")\n",
    "    print(\"2. Copy your brain MRI images into the folders\")\n",
    "    print(\"3. Run the preprocessing pipeline (Cell 3)\")\n",
    "elif not (base_path / 'dataset/train/healthy').exists():\n",
    "    print(\"1. Run the preprocessing pipeline (Cell 3)\")\n",
    "else:\n",
    "    print(\"âœ… Dataset is ready! You can proceed with training.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5fa3c",
   "metadata": {},
   "source": [
    "## ðŸ“Š Augmentation-Logik ErklÃ¤rung\n",
    "\n",
    "**Wie entstehen 10.542 Training Images aus 1.757 raw Images?**\n",
    "\n",
    "### Schritt-fÃ¼r-Schritt Berechnung:\n",
    "\n",
    "```\n",
    "STEP 1: Laden & Cleaning\n",
    "â”œâ”€ Raw no_tumor:           1.757 images\n",
    "â””â”€ Nach Cleaning:          ~1.757 images (kaum dropped)\n",
    "\n",
    "STEP 2: Pre-Split Augmentation\n",
    "â”œâ”€ Ziel:                   5.000 Test Samples\n",
    "â”œâ”€ BenÃ¶tigt Total:         6.250 (125% fÃ¼r 80/20 Split)\n",
    "â”œâ”€ Augmentations/Image:    6.250 Ã· 1.757 = 3Ã— pro Bild\n",
    "â”œâ”€ Berechnung:             1.757 Ã— (1 Original + 3 Augmented) = 7.028\n",
    "â””â”€ Nach Pre-Split Aug:     7.028 images\n",
    "\n",
    "STEP 3: Train/Test Split\n",
    "â”œâ”€ Ziel Test Samples:      5.000\n",
    "â”œâ”€ VerfÃ¼gbar:              7.028\n",
    "â”œâ”€ Split Ratio Calc:       1 - (5000/7028) = 0.289 â†’ clamped zu 0.5\n",
    "â”œâ”€ TatsÃ¤chlicher Split:    50% / 50%\n",
    "â”œâ”€ Train Split:            3.514 images\n",
    "â””â”€ Test Split:             3.514 images\n",
    "\n",
    "STEP 4: Train Augmentation (augment_train=True)\n",
    "â”œâ”€ Strategie:              Original + 2Ã— Augmentationen pro Bild\n",
    "â”œâ”€ Berechnung:             3.514 Ã— (1 + 2) = 10.542\n",
    "â””â”€ Final Train:            10.542 images âœ…\n",
    "```\n",
    "\n",
    "### Zusammenfassung:\n",
    "\n",
    "| Phase | Input | Multiplikator | Output |\n",
    "|-------|-------|---------------|--------|\n",
    "| Raw Data | 1.757 | - | 1.757 |\n",
    "| Pre-Split Aug | 1.757 | Ã—4 (1+3) | 7.028 |\n",
    "| Split (50%) | 7.028 | Ã·2 | 3.514 |\n",
    "| Train Aug | 3.514 | Ã—3 (1+2) | **10.542** âœ… |\n",
    "\n",
    "**Warum 2Ã— Augmentation?**\n",
    "- Healthy Train Samples brauchen **starke Augmentation** fÃ¼r robustes Training\n",
    "- Tumor Test Samples: **KEINE Augmentation** (Anomaly Class bleibt original)\n",
    "\n",
    "**Warum nur 3.514 Test statt 5.000?**\n",
    "- âš ï¸ Nur 1.757 raw Images verfÃ¼gbar\n",
    "- Pre-Split Augmentation reicht nicht fÃ¼r 5.000 Test\n",
    "- **LÃ¶sung**: Mehr Images zu `dataset_raw/no_tumor/` hinzufÃ¼gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b71e4",
   "metadata": {},
   "source": [
    "## âš ï¸ Vorbereitung erforderlich\n",
    "\n",
    "Bevor du die Preprocessing-Pipeline ausfÃ¼hren kannst, **erstelle bitte folgende Ordnerstruktur**:\n",
    "\n",
    "```\n",
    "Scientific/\n",
    "  dataset_raw/\n",
    "    no_tumor/        â† Platziere hier alle gesunden Brain MRI Bilder\n",
    "    glioma/          â† Platziere hier Glioma-Tumor Bilder\n",
    "    meningioma/      â† Platziere hier Meningioma-Tumor Bilder\n",
    "    pituitary/       â† Platziere hier Pituitary-Tumor Bilder\n",
    "```\n",
    "\n",
    "**Alternative:** Wenn deine Bilder bereits in anderen Ordnern liegen, passe die Pfade in der nÃ¤chsten Zelle entsprechend an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dca25",
   "metadata": {},
   "source": [
    "# ðŸ“Š MRI Preprocessing Pipeline\n",
    "\n",
    "This section implements a complete medical-grade preprocessing pipeline for Brain MRI images:\n",
    "\n",
    "**Features:**\n",
    "- âœ… Intensity Normalization (Z-Score, Min-Max, Combined)\n",
    "- âœ… CLAHE Histogram Equalization\n",
    "- âœ… Spatial Normalization (256Ã—256)\n",
    "- âœ… Data Cleaning (artifact removal)\n",
    "- âœ… Smart Train/Test Splitting\n",
    "- âœ… Augmentation (only for healthy train samples)\n",
    "- âœ… N4 Bias Correction (optional, if SimpleITK available)\n",
    "- âœ… Skull Stripping (optional)\n",
    "\n",
    "**Output Structure:**\n",
    "```\n",
    "dataset/\n",
    "  train/healthy/     â† augmented healthy samples\n",
    "  test/healthy/      â† healthy test samples  \n",
    "  test/tumor/        â† all tumor types\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de33c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading Preprocessed Brain Tumor Dataset...\n",
      "\n",
      "ðŸŸ¢ Healthy samples (label=0):\n",
      "   Loaded 10542 images from healthy (label=0)\n",
      "   Loaded 3514 images from healthy (label=0)\n",
      "\n",
      "ðŸ”´ Tumor samples (label=1):\n",
      "   Loaded 8803 images from tumor (label=1)\n",
      "\n",
      "âœ… Dataset ready:\n",
      "   Train (healthy only): 10542 samples\n",
      "   Test (healthy + tumor): 12317 samples\n",
      "      â””â”€ Healthy: 3514\n",
      "      â””â”€ Tumor: 8803\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Dataset Loader for EfficientAD (using preprocessed data)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Dataset for preprocessed Brain Tumor images\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, folder_path, label, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_path: Path to preprocessed folder (e.g., dataset/train/healthy)\n",
    "            label: 0 for healthy, 1 for tumor\n",
    "            transform: Additional transformations (minimal, data already preprocessed)\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.label = label\n",
    "        self.image_paths = []\n",
    "        \n",
    "        folder_path = Path(folder_path)\n",
    "        if folder_path.exists():\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                self.image_paths.extend(list(folder_path.glob(ext)))\n",
    "        \n",
    "        print(f\"   Loaded {len(self.image_paths)} images from {folder_path.name} (label={label})\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path)  # no grayscale conversion\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.label\n",
    "\n",
    "\n",
    "# Minimal transform (data already preprocessed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # No normalization here; raw pixel values preserved\n",
    "])\n",
    "\n",
    "# Base path to preprocessed dataset\n",
    "base_path = Path(r\"dataset_preprocessed\") #Pfad zu dataset preprocessed\n",
    "\n",
    "\n",
    "print(\"ðŸ“Š Loading Preprocessed Brain Tumor Dataset...\")\n",
    "print(\"\\nðŸŸ¢ Healthy samples (label=0):\")\n",
    "healthy_train = BrainTumorDataset(base_path / 'train/healthy', label=0, transform=transform)\n",
    "healthy_test = BrainTumorDataset(base_path / 'test/healthy', label=0, transform=transform)\n",
    "\n",
    "print(\"\\nðŸ”´ Tumor samples (label=1):\")\n",
    "tumor_test = BrainTumorDataset(base_path / 'test/tumor', label=1, transform=transform)\n",
    "\n",
    "# Combine datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# For EfficientAD: Train ONLY on healthy samples\n",
    "train_set = healthy_train\n",
    "\n",
    "# Test on both healthy and tumor samples\n",
    "test_set = ConcatDataset([healthy_test, tumor_test])\n",
    "\n",
    "# âš ï¸ CHECK: Prevent DataLoader error if no healthy images exist\n",
    "if len(train_set) == 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âŒ ERROR: No healthy training images found!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"ðŸ”§ Required actions:\")\n",
    "    print(\"1. Add healthy brain MRI images to:\")\n",
    "    print(\"   dataset_raw/no_tumor/\")\n",
    "    print(\"2. Re-run the preprocessing pipeline (Cell 3)\")\n",
    "    print(\"3. Then re-run this cell\")\n",
    "    print(\"=\"*60)\n",
    "    raise ValueError(\"Cannot create DataLoader: No healthy training images available. \"\n",
    "                     \"Please add images to dataset_raw/no_tumor/ and run preprocessing.\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"\\nâœ… Dataset ready:\")\n",
    "print(f\"   Train (healthy only): {len(train_set)} samples\")\n",
    "print(f\"   Test (healthy + tumor): {len(test_set)} samples\")\n",
    "print(f\"      â””â”€ Healthy: {len(healthy_test)}\")\n",
    "print(f\"      â””â”€ Tumor: {len(tumor_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EfficientAD Models\n",
    "# Teacher = ResNet18 Feature Extractor\n",
    "# Student = Small CNN to mimic Teacher\n",
    "# Autoencoder = Reconstruction branch\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------\n",
    "# Teacher Network (fixed)\n",
    "# ------------------------------\n",
    "class Teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.model.fc = nn.Identity()  # remove classification layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Student Network (trainable)\n",
    "# ------------------------------\n",
    "class Student(nn.Module):\n",
    "    def __init__(self, feature_dim=512):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 64 * 64, feature_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Autoencoder (Reconstruction)\n",
    "# ------------------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 2, stride=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "teacher = Teacher().to(device).eval()\n",
    "student = Student().to(device)\n",
    "autoencoder = Autoencoder().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e61a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | FD Loss=22.4981 | AE Loss=24.1536\n",
      "Epoch 2/50 | FD Loss=8.1264 | AE Loss=3.0867\n",
      "Epoch 3/50 | FD Loss=5.2951 | AE Loss=2.3485\n",
      "Epoch 4/50 | FD Loss=3.8729 | AE Loss=2.0029\n",
      "Epoch 5/50 | FD Loss=3.0507 | AE Loss=1.8266\n",
      "Epoch 6/50 | FD Loss=2.4683 | AE Loss=1.7097\n",
      "Epoch 7/50 | FD Loss=2.0473 | AE Loss=1.6170\n",
      "Epoch 8/50 | FD Loss=1.7770 | AE Loss=1.5386\n",
      "Epoch 9/50 | FD Loss=1.5914 | AE Loss=1.4704\n",
      "Epoch 10/50 | FD Loss=1.3930 | AE Loss=1.4105\n",
      "Epoch 11/50 | FD Loss=1.2597 | AE Loss=1.3574\n",
      "Epoch 12/50 | FD Loss=1.1226 | AE Loss=1.3091\n",
      "Epoch 13/50 | FD Loss=1.0418 | AE Loss=1.2634\n",
      "Epoch 14/50 | FD Loss=0.9464 | AE Loss=1.2229\n",
      "Epoch 15/50 | FD Loss=0.8827 | AE Loss=1.1844\n",
      "Epoch 16/50 | FD Loss=0.8140 | AE Loss=1.1499\n",
      "Epoch 17/50 | FD Loss=0.7705 | AE Loss=1.1188\n",
      "Epoch 18/50 | FD Loss=0.7242 | AE Loss=1.0909\n",
      "Epoch 19/50 | FD Loss=0.6821 | AE Loss=1.0654\n",
      "Epoch 20/50 | FD Loss=0.6238 | AE Loss=1.0427\n",
      "Epoch 21/50 | FD Loss=0.5695 | AE Loss=1.0221\n",
      "Epoch 22/50 | FD Loss=0.5567 | AE Loss=1.0032\n",
      "Epoch 23/50 | FD Loss=0.5463 | AE Loss=0.9862\n",
      "Epoch 24/50 | FD Loss=0.5190 | AE Loss=0.9705\n",
      "Epoch 25/50 | FD Loss=0.4832 | AE Loss=0.9563\n",
      "Epoch 26/50 | FD Loss=0.4449 | AE Loss=0.9430\n",
      "Epoch 27/50 | FD Loss=0.4344 | AE Loss=0.9307\n",
      "Epoch 28/50 | FD Loss=0.4088 | AE Loss=0.9193\n",
      "Epoch 29/50 | FD Loss=0.4007 | AE Loss=0.9089\n",
      "Epoch 30/50 | FD Loss=0.3836 | AE Loss=0.8988\n",
      "Epoch 31/50 | FD Loss=0.3728 | AE Loss=0.8897\n",
      "Epoch 32/50 | FD Loss=0.3557 | AE Loss=0.8808\n",
      "Epoch 33/50 | FD Loss=0.3489 | AE Loss=0.8725\n",
      "Epoch 34/50 | FD Loss=0.3251 | AE Loss=0.8648\n",
      "Epoch 35/50 | FD Loss=0.3132 | AE Loss=0.8573\n",
      "Epoch 36/50 | FD Loss=0.3055 | AE Loss=0.8505\n",
      "Epoch 37/50 | FD Loss=0.2993 | AE Loss=0.8439\n",
      "Epoch 38/50 | FD Loss=0.2893 | AE Loss=0.8379\n",
      "Epoch 39/50 | FD Loss=0.2655 | AE Loss=0.8320\n",
      "Epoch 40/50 | FD Loss=0.2710 | AE Loss=0.8268\n",
      "Epoch 41/50 | FD Loss=0.2617 | AE Loss=0.8214\n",
      "Epoch 42/50 | FD Loss=0.2723 | AE Loss=0.8165\n",
      "Epoch 43/50 | FD Loss=0.2406 | AE Loss=0.8117\n",
      "Epoch 44/50 | FD Loss=0.2348 | AE Loss=0.8071\n",
      "Epoch 45/50 | FD Loss=0.2265 | AE Loss=0.8029\n",
      "Epoch 46/50 | FD Loss=0.2181 | AE Loss=0.7985\n",
      "Epoch 47/50 | FD Loss=0.2287 | AE Loss=0.7945\n",
      "Epoch 48/50 | FD Loss=0.2184 | AE Loss=0.7907\n",
      "Epoch 49/50 | FD Loss=0.2080 | AE Loss=0.7869\n",
      "Epoch 50/50 | FD Loss=0.2044 | AE Loss=0.7832\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Training EfficientAD\n",
    "# ============================================================\n",
    "\n",
    "opt_student = optim.Adam(student.parameters(), lr=1e-4)\n",
    "opt_ae = optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    student.train()\n",
    "    autoencoder.train()\n",
    "    \n",
    "    total_fd_loss = 0\n",
    "    total_ae_loss = 0\n",
    "    \n",
    "    for imgs, _ in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # ---- Feature Distillation Loss ----\n",
    "        with torch.no_grad():\n",
    "            teacher_feat = teacher(imgs)\n",
    "\n",
    "        student_feat = student(imgs)\n",
    "        loss_fd = mse(student_feat, teacher_feat)\n",
    "\n",
    "        opt_student.zero_grad()\n",
    "        loss_fd.backward()\n",
    "        opt_student.step()\n",
    "        \n",
    "        # ---- Autoencoder Loss ----\n",
    "        recon = autoencoder(imgs)\n",
    "        loss_ae = mse(recon, imgs)\n",
    "\n",
    "        opt_ae.zero_grad()\n",
    "        loss_ae.backward()\n",
    "        opt_ae.step()\n",
    "\n",
    "        total_fd_loss += loss_fd.item()\n",
    "        total_ae_loss += loss_ae.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | FD Loss={total_fd_loss:.4f} | AE Loss={total_ae_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Compute Anomaly Scores\n",
    "# ============================================================\n",
    "\n",
    "def anomaly_score(img):\n",
    "    with torch.no_grad():\n",
    "        teacher_feat = teacher(img)\n",
    "        student_feat = student(img)\n",
    "        recon = autoencoder(img)\n",
    "\n",
    "    fd_error = torch.mean((teacher_feat - student_feat) ** 2).item()\n",
    "    ae_error = torch.mean((img - recon) ** 2).item()\n",
    "\n",
    "    # Weighting (can be tuned)\n",
    "    return fd_error * 0.7 + ae_error * 0.3\n",
    "\n",
    "\n",
    "scores = []\n",
    "labels = []\n",
    "\n",
    "for imgs, lbls in test_loader:\n",
    "    imgs = imgs.to(device)\n",
    "    for i in range(len(imgs)):\n",
    "        score = anomaly_score(imgs[i].unsqueeze(0))\n",
    "        scores.append(score)\n",
    "\n",
    "        label = lbls[i].item()  # 0 = healthy, 1 = tumor\n",
    "        labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a094dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAHWCAYAAAA2Of5hAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZ7lJREFUeJzt3Qd8k9X3P/DDKHvvQtl7742gyBCUvWQLCDIEZIgMGYIMBRkyZW+BIiB7yEZAZG9QQBkylVEoq23+r8/5/pNfWtLSlKbPk+Tzfr0CydOMmzzJk5Nz7z03lsVisQgRERERGSq2sQ9PRERERMCgjIiIiMgEGJQRERERmQCDMiIiIiITYFBGREREZAIMyoiIiIhMgEEZERERkQkwKCMiIiIyAQZlRERERCbAoIyIZOzYsZIjRw6JEyeOFCtWTLcFBQVJv379JHPmzBI7dmypX7++bo8VK5YMGzbMqfvftWuX3g7/k+tgv+B1JrLKli2bfPTRR0Y3gyKJQRm91vz58/VAbz3FjRtXMmXKpB/0GzduOLwNVu9atGiRVK5cWVKkSCGJEiWSwoULy/Dhw+XJkyfhPtbq1aulVq1akiZNGokXL55kzJhRmjZtKjt27IhUW589eyYTJkyQsmXLSvLkySVBggSSJ08e+fTTT+XixYviLf76669Q+yzsacyYMbbrbt26VYOvihUryrx582TUqFG6fe7cuRqsNW7cWBYsWCC9evUSs0Pb16xZE+F1pk2bpq8B3iPhCft+T5UqlZQsWVJ69uwpZ8+edeoL0f6+8H7MnTu3fP755/Lff/+Jmb399tsRvoesJ2cDdLMf37CPcNypWbOmfP/99xIQEBDl+8Z7Ba8PPo+utH//fn2cBw8euPRxyPVice1LisxBq127dhpQZc+eXQOfgwcP6nZ86Zw+fVoPZFbBwcHSokULWbFihbz11lvSsGFDDcr27t0rS5culQIFCsgvv/wi6dOnt90Gb8P27dvrfRYvXlwDgQwZMsjNmzc1UDty5Ij8+uuvUqFChXDbee/ePXnvvff0uh988IFUq1ZNkiRJIhcuXJBly5bJrVu35MWLF+IN8CWAfdW8eXOpXbv2K3/Ha1ywYEE9379/fw2+nj59qoGw1Ycffij79u2T69evh7ot9j8CFZwiKyQkRF973D+ybq6C/Y33Dt5H4UHw+c8//+hr9Mcff0iuXLleuQ6+nKtXry5t2rTR9+bDhw/lxIkT4u/vrz8qvvnmG+ndu/dr24PPR8qUKaVPnz621w7vz9mzZ+s+OHTokEQnZDdxsv88RtW2bdvk9u3btsu///67BikDBw6U/Pnz27YXKVJET55yfHv58qUeK5DVxWuQJUsWWbt2bZSe48qVK6VJkyayc+dODXJdZdy4cRroX7lyRd9z9p4/f66fOR8fH5c9PkUjBGVEEZk3bx4Cd8vvv/8eavsXX3yh25cvXx5q+6hRo3R73759X7mvtWvXWmLHjm157733Qm0fO3as3uazzz6zhISEvHK7hQsXWn777bcI2/n+++/rfa9cufKVvz179szSp08fS3R4+fKl5fnz5xYzu3Llir6eeF1fp127dpbEiRO/sv2dd96xFCxY0OJO8Dzatm0b7t8vX76sr8uqVassadOmtQwbNszh9XCdbt26vbL93r17lvLly+vfN2zY8Nr2ZM2aVd+XYeGzgfu4ePFihLd//PixxSz8/f21zTt37rS4m4hex/COb7B9+3ZLwoQJdT8GBgaa9jWzHj/xuSf3xqCMXiu8g9b69et1O4IwKxy4UqZMacmTJ48GL+EFAbjdgQMHbLdJlSqVJV++fJagoKAotfHgwYN6nx07dozU9atUqaKnsPCFjgOwo+BmwoQJlhw5cmjgh8eLEyeOwy/18+fP620mT55s23b//n1Lz549LX5+fpZ48eJZcubMaRkzZowlODjYYmRQhuuEPVn3d9iT9YsF54cOHRrqfq5fv25p3769xdfXV59ftmzZLJ07d7YFr7itoy8nvI41a9a0JEuWTL/8KleubNm3b1+o6+CxcNs//vhD90/y5Mn1+h999JHlyZMnET6XsAHaiBEj9P2JdnXp0sWSO3dup4Iy+Pvvvy1x48a1VKhQwRLVoGzcuHH6GAgSrdBWBJV//vmnpVatWpYkSZJY6tWrp3/bs2ePpXHjxpbMmTPr64v3EX7AhA0UrK+Vo+eyevVqDbJx+wIFClg2bdpkedMAI+znJTLtWLFihSV//vyWBAkSWMqVK2c5efKk/n3GjBn6uYgfP75+Nh0FGLhtiRIl9LapU6e2tGzZUt979iJ6HZ0Nyux/ZM6cOTPU9nPnzlkaNWqk7ye0uWTJkpaff/75lfsN73MEGzdutFSqVMmSKFEibWft2rUtp0+ffqUNeKwmTZpY0qRJo88dx9eBAweGeq3DnqyvH/ZP2M/BpUuX9P2EtuNzV7ZsWT2e27N+ZvGj++uvv7ZkypRJn2fVqlX1s0iuEfn+B6IwrOMk0D1jhe6u+/fv69ib8Lq30CWEsUvr16+XcuXK6W0wvuazzz7TgeZRge4FaN26tbgC2ouup06dOkn8+PHF19dXqlSpol20Q4cODXXd5cuX6/NAtwUEBgbqdTH+7pNPPtHuEIwBGTBggHbPTpw40SVttj42unXDwjg/7B+M+5s5c6Z2o6FLDdCthu0jR46Ux48fy+jRo3W7fZeVPXQFlilTRsez4PXJly+fPld03eDx7btE7WGcIMYPYqwWXkN0seB1rlq1qnZ14z7tYWwhupfQnqNHj2p706VLp12JgDZ//PHHeju0A3LmzBnqPpYsWaLd6WgTunanT5+u3XKlS5eO9GuK/Yf9iS6pR48eSbJkySK8PrrDrPsA76Fjx47J+PHjdbwlno89dD1iLFOlSpW0Swrd/oBuU7yWXbp0kdSpU+v+mjx5snYt42+vg8/YqlWrpGvXrpI0aVLthmzUqJFcvXpV7y+mYL/is9qtWze9jH2JoQYY04ixfmgfjh/ffvutDmewH0tq7WbEvsLt0LU6adIkHdaA1xTv6de9jlGBYwq6bDH2smPHjrrtzJkz2g2OsbXo/k+cOLEeCzAZ5qeffpIGDRro/u3Ro8crXb7W//F+bdu2rbYT72HsX7wf0WY8H2s35MmTJ3UYCLof8b7G9kuXLsm6dev0M4r3M8bL/vjjjzqeFuNxIW3atA6fD143DAPB46F92P8YM1q3bl39zKLt9jD+FJ/Nvn37ajc+9k3Lli3lt99+i/JrShFwUbBHHsT6i++XX36x3L1713Lt2jXtIkT3D3454bLVxIkT9br4VR6e//77T6/TsGFDvTxp0qTX3uZ1GjRooPeBjJQrMmXIzNy5cyfUdX/44Qf926lTp0JtRxYCvybtszP45R62q6p///6abbt69aolulnbHd7JmqW0PmdH3Zd4fRx1X4bNlLVp00azh44yDdau6LCZMmxHlgpZMvvuamR+smfPbqlevbptmzUTgExc2H2ObElkuy8PHz6s97Nt2zZbG5BxQgbTmUwZ4Da4zokTJywRwXvJ0etfsWJF7Qq1h3bjb3hfhOWo62z06NGWWLFiaebudRkqZMeQObJCu8Nmc2MiU4bjhX0GzPoZypAhg+XRo0e27QMGDAiV7Xnx4oUlXbp0lkKFClmePn36SrZ+yJAhkXodo5IpA2Rnixcvbrv87rvvWgoXLqzDIqzwfkL21D77Gl73ZUBAgCVFihSvZPZv3bqlj2W/HdnjpEmThtrP1seLTPdl2EwZMqy47t69e0O1B587ZLit2XvrZxZZTfvhGtbjddjjHkUPzr6kSMPAefz6QokEDKbGr0P86vXz87NdxzpTCb/Gw2P9G7IM9v9HdJvXiY77iAiyCmF/eeIXKrJNyIxZYdIDZlw1a9bMtg2ZDPzSRUYRGRPrCa8nJkXs2bNHXAW/rDFYOewJky2iAwbwY7ZjnTp1pFSpUq/8PbzyDMePH9dB9pgQ8u+//9peEwyif/fdd/U1wX3b69y5c6jLeE1xW+u+fx1kyTC55J133rG1DfsJk0CwH5ydUACRmZmHWZ7W1x3ZYWQ3kGlBZgKTK8JCNiyshAkT2s7jNcJrhWwHYh1kVV4H7zX7rCEGrSPDd/nyZYlJ2Lf2A9GtM2Dx+bL/7Fq3W9t3+PBhuXPnjmbS7CcxvP/++5qZ3bBhQ6Rex6jC/rbua2T1kcFD5hbbrO9dvBeR9cL7OrxZ6VZ4LyCzjGyt/TEBGXY8d2Rh4e7du/pZQNYQGVp7US19snHjRs0mIyNn//xwrEDvR9jZxchO2me78bmDmH7veAt2X1KkTZ06VctLIIWNcgk4WKArz571wBrRl1XYwM3a/fMmU8/t78O+GyO6hO1mAnQT4EsG3RYjRozQbQjQEKghYLPCQRpdEOF1J+DLJjx4rR19cQPu73XdvSi/gC9kV8GXBoKiQoUKOXU7vCaA7puInrt913jYLyXr39Dd9bouRARdCL4QkGGGmhW+AL/77jvZvn271KhRI9LtR7duZH8E4H1ivw8QSOTNm1d/2KALtnv37ra/4b1j/yPHCt2MQ4YM0R9BeL5hX6fXCfvaWV+/sPflamHbgbI1gB96jrZb2/f333/r/3jdwkJQhu5Ze+G9jlGF/Y2ucvjzzz81GB48eLCewvtMo2vzde9/dNU7Yn0/WwMfZz9fEcFr6agcjLVbFX+3f7yIPncU/RiUUaTh15U1G4KxE/ilhUwHSk5YMwfWDzaCEGux0bDwN7Bma3BQhVOnToV7m9exvw/rL7mI4Femo2ow4WVM7DMV9lA2Ar8kkflB0VUEaAjUrOM6ABkflFfAuBlHEOiGB2PzMN7DEUfT392FNQuGUhzWYrVhWd9TVuEFoJGp6oPMBsbvITDDyVEWzZmgDBlRtMdRsB4ZeI8AftjYB2X4kRO2ZAjek3j/IEPzxRdf6HsdWWpkY1ArMGxG0ZE3ee0iEl62JrzPUXjtiO72OXodowrj9hD4WkunWF9vjLFCZswRR2VW7FnvA+PKUPonLGfKzbiaq9475Jh59jy5FXxQMdgWmYcpU6boYFdAoIZMFeqRDRo0yOEHeuHChfo/Bvhab4NfXxioigGxURnsj+4ztGfx4sWRCsrweI7S79Zf5JGFIBKD961dmBhwiwH89tBthF/aUclYIZBr1aqVw785OpjHNGTr8KseQYozrF1puG10ZvLCCxIQdCHTgWxvWBgAj1p4M2bMCDf4Dpu12r17t5QvXz7K3eUYiG6fcYsIfmjgfYXgHJNk7LvAjIbPkaOCpc5+jl4na9as+j9+AIbNLmGb9e+ugMAJrAEYVr4ADLx/3Xs3vPej9f2P92RE92F9rNd9vpzpysRrhdcsrPPnz9v+TsbhmDKKMhRDRPYMswcxqwwwywm/IPGhR1AWFsZ+YBYVDnCYeWm9DTIA586d0/8d/QJDsBVRoU18QaJwLLqDHFV0R+FStMv+oIiDELrfrFAcFDO5nIEAFM8FGTJkYDD2Imy2D2NPDhw4IFu2bHnl9vhCs35BO4JsIg7ajk7RUSD0TVmXX8JMMIz7ieyvacy4xD7AzDhHgYn9fnEGMkhhgwR0/yLwwo8AdBmGPWG1B3R7W2fwRgTZKowDQibI0fs7svB6QdGiRV97XeuPFPvXEucx89Bo2IfIIlmz32At+BydkKFHAIPAGcVQrTZt2qTHDXQJuwIyrBiagIwoZhwC2oFj3w8//KDPNaL3Lt6PEPY9iWMGfpBgBQrMzg3vPvCjB7M4MVwEPwbs2b8fwnscR1BMGsdSHJPsxyliFjYy79E13pSihpkyeiOoIo3SDwi0rAOxkTXD4GNM88YHH4N4kYHAuA8EV+jiDNslh/vB4GeM78EgV2tFf1TWRpCFgwjKSEQEGTh0QWE8FzJn6CLCwQrjNxAw4QCKIAAwcBZlCXBw7NChg44BwQEfVe4jO3DcCoPFkc3ClH7cX9gxbXhu+MJHUIDuJgQkOAgiA4Ip6Bhca9/dGZ1QOgKvuaMvUwSy0QFfLCgXgDIRGCyM/YvXGhMcsM8djfFDMIcAGiUx8JqjCxhjcNAlh/2PLyxr4OIMvLZYLQL7Fkvl4MsUry+CLgysdwQ/DvDlh2ya/QQNZKfw2uHLD+8Ja0V/BJG4f/wIiAw8J+s+wI8D3A++0LHP7bsuw4PuSuwv/KjAfeG1QdkFM4zpQfc9fkihjALKK1jLOqBLHu+96IKsFI4neJ/gfYbA2FoSA4FEdCwBhgAPP9TwIwn3jYAM2UhkjvD5tf8RhIwrMvxYOg5lMpDRwm1wvEN3J/YxoGseQTXajuAV3arI9CGww+uEchslSpTQ1xHvQQRe+OGKchvogQCU1MBj4Xr4fFnf07gehk1Y3/eAHwq4L7xeOAZagzV7OD6jVwKfPewzLCGG4zGGQ+B95coVNygSomkWJ3mwiKaMY/o0Cj7iZF/4FdtxO0z9RzkJFDxEeYWvvvoqwuraKLVRo0YNLSaLAp0oRtqsWTPLrl27ItVWlA5AYc7SpUtrMUaUAsAU9e7du4cqCQCLFy/WYrC4TrFixSxbtmyJsHhseDCVHwUYcT3cpyOYco5p/rly5dLHQxFITJ9HWzHdP6ZLYthPkX/TkhiA6foojWEtk4LXFSUlXlc89tixY1oaBaUtcDu89k2bNtVK6mHLK6Aci6P3pX0ZABTuRQkB6/7Ac6tTp46+/+wLzYaFQrQ+Pj62MhX2rxXKfaB8AUoioBTGmTNnLJEVtiQG7gulHZo3b/7K+zG8/QBnz561VKtWTd/TeO+gZIK1rAVeh7CvVWTKezgqKhqR8Mo7bN26VUtV4H2dN29e/QxEth3hfb6s7xc8pj0UMsV+wHsFx4iIisdGVtgir3geKNGBsiwo/2BfqiNsAVa853FdvHdQXPWDDz54ZUWRWbNm6ecB5W/Cvn44j7IwKIOB9yiOo3gvonyLPRSURQkYvA9xPbzOgwcPDnUdlN5BG/Aei2zxWOv9lSlTJtzisWH3gXWf2b/vKPpw7UsiIiIiE2CekoiIiMgEGJQRERERmQCDMiIiIiITYFBGREREZAIMyoiIiIhMgEEZERERkQl4XfFYrDn2zz//6PIozixNQURERBQVqD6GItYoah1RgV6vC8oQkGXOnNnoZhAREZGXuXbtmvj5+YX7d68LyqwLCOOFwXIlRERERK6EpdqQELLGIOHxuqDM2mWJgIxBGREREcWU1w2b4kB/IiIiIhNgUEZERERkAgzKiIiIiEyAQRkRERGRCTAoIyIiIjIBBmVEREREJsCgjIiIiMgEGJQRERERmQCDMiIiIiITYFBGRERE5O1B2Z49e6ROnTq6ajqWHlizZs1rb7Nr1y4pUaKExI8fX3LlyiXz58+PkbYSEREReWxQ9uTJEylatKhMnTo1Ute/cuWKvP/++/LOO+/I8ePH5bPPPpOPP/5YtmzZ4vK2EhEREbmSoQuS16pVS0+RNWPGDMmePbt89913ejl//vyyb98+mTBhgtSsWdOFLfU+FotFnr4MNroZREREMSKhT5zXLhju0UGZsw4cOCDVqlULtQ3BGDJm4Xn+/LmerB49euTSNnpC8GWxiDSZcUDO3uRrRUREnssS9EJixY2n588OrymJ4hkbFrlVUHbr1i1Jnz59qG24jEDr6dOnkjBhwlduM3r0aPnqq69isJXuE4gx+CIiIm/1/MZ5ubd+nKSo3EYS568sZuBWQVlUDBgwQHr37m27jAAuc+bM4q3BWOCL4EgHYgV8k4l/5/JicDaXiIgo2gQFBcnYb8bI6B+/luDgYMn49xb5dfkI7b40mlsFZRkyZJDbt2+H2obLyZIlc5glA8zSxMmbvS4YCy/4MkP/OhERUXTBhMFWrVrJ/v379XKLFi1k2rRpkiTB/7owjeZWQVn58uVl48aNobZt27ZNt5NjISEW+WDyvleCMftAjMEXERF5enJi8eLF0q1bNwkICNBkDoKxli1bipkYGpQ9fvxY/vzzz1ARLEpdpEqVSrJkyaJdjzdu3JCFCxfq3zt37ixTpkyRfv36Sfv27WXHjh2yYsUK2bBhg4HPwtzZMQRkV+49eSUYSxSPgRgREXmHEydOSJs2bfR8pUqVZNGiRZItWzYxG0ODssOHD2vNMSvr2K+2bdtqUdibN2/K1atXbX9HOQwEYL169ZJJkyaJn5+fzJ49m+UwHARkjWcckCN/37dty54msazvXonBGBEReZ1ixYpJnz59JGXKlNK/f3+JE8f48WOOxLLgG9yLYKB/8uTJ5eHDh5q+9ERPngdJwaFbQmXHEJDFjs1gjIiIPN+LFy9k5MiR2quWNWtWt4k93GpMGUV+DJnV4S+rSerE8ZgdIyIir3DhwgUdK3bkyBHZuXOnLs8YO7Z7LPXtHq2kSEHS034MGTJkDMiIiMhbvgNnzZql62MjIENXZc+ePd0mIANmyjwIBvZbZ1lax5AxICMiIk937949XQv7559/1stVq1aVBQsW6Nhzd8KgzIN+IaAOmRXHkBERkTc4c+aMLsGIVX98fHx0JR9MCHSnDJkVgzIPzJKh2xKzLImIiDxdzpw5JW3atNpduXTpUp1p6a4YlHlglux/RWGZJSMiIs908eJFyZEjh8SNG1cSJEgg69at08AsUaJE4s7cL7dHr8Di4sySERGRNyQhvv/+eylSpIiMGTPGth1lL9w9IANmyjyAfaU5ZsmIiMgT3bp1S9q1ayebN2/Wy7///ruEhIS45dix8HjOM/FSYbsuGY8REZGnWbdunRQuXFgDMnRXTp48WdasWeNRARkwU+ZhXZdYXJyIiMgTBAYG6vJIM2bM0MvotsRg/oIFC4on8qwQ0wux65KIiDzV33//rWthA4KzQ4cOeWxABsyUuTF2XRIRkSfLnz+/ZskyZcqktcg8HTNlHlSbjF2XRETkzq5duyY1atSQAwf+L+HQtm1brwjIgJkyN8XaZERE5En8/f3lk08+kfv37+tMyxMnTnjd9xozZW6KtcmIiMgTBAQEaKmLpk2bakBWunRp+emnn7wuIAMGZR6AWTIiInJHBw8e1GWRMJg/VqxYMmjQIPn1118ld+7c4o3YfekBGI8REZG7OXLkiFSqVEmCg4MlS5YssnjxYnnrrbfEmzEo84BSGERERO6mRIkSUqtWLUmaNKlMmzZNUqRIId6OQZkHDPInIiJyh++uFStWyHvvvSfJkyfX7koM7keFfvofjilzQ6ziT0RE7uTBgwfSokUL+fDDD6V79+627QzIQmOmzA2xij8REbmL3bt3S+vWrbUGWZw4cSRPnjyaNeN316sYlLkZVvEnIiJ38OLFCxk2bJiMGTNGv7ty5swpS5YskbJlyxrdNNNiUOZm2HVJRERm99dff0mTJk3k8OHDerl9+/YyceJEHdRP4WNQ5mbYdUlERGaXOHFiuX79uqRMmVJmzpwpjRs3NrpJboFBmRth1yUREZm5Mr81E5Y2bVpZvXq1+Pn56Ykih7Mv3Qi7LomIyIy2bt0qefPmlaVLl9q2lStXjgGZkxiUuSl2XRIRkdGePXsmvXv3lpo1a8rNmzdl8uTJ2qtDUcOgzE0xHiMiIiOdOXNGZ1JOmDBBL3ft2lW2b9/OhMEbYFDmRvjjg4iIjIZMGDJiJUuWlJMnT+r4sXXr1snUqVMlUaJERjfPrXGgv5vg0kpERGQGKHPRo0cPPY+1K+fNmyfp06c3ulkegUGZm+AgfyIiMoPSpUvLgAEDJGPGjNKtWzd2V0Yjdl+6IQ7yJyKimBIYGCi9evWSK1eu2LaNGjVKPv30U34XRTNmytwQPwNERBQTjh07pguJnz9/Xrst9+zZw0DMhZgpIyIiolBCQkJk7NixOrsSAZmvr68MHTqUAZmLMVPmJjjzkoiIYgKWR2rbtq3s2LFDLzdo0EBmzZolqVOnNrppHo9BmRvgzEsiIooJx48fl6pVq8r9+/e1vMX333+vi4kzQxYzGJS5Ac68JCKimJA/f37JkiWL5MqVS5YsWSK5c+c2uklehUGZm+HMSyIiiu7sWKFChSRu3LgSP3582bhxoxaE9fHxMbppXocD/d0M4zEiIooOQUFBMnz4cClVqpSMHDnSth31xxiQGYOZMiIiIi+DmmOtWrWS/fv36+VLly7p+GX2xBiLmTIiIiIvgcBr0aJFUrRoUQ3IkiVLJosXL5aFCxcyIDMBZsqIiIi8wIMHD6RLly6ybNkyvVyxYkUNyLJly2Z00+j/Y6aMiIjIC9y8eVPWrFkjceLEkREjRsiuXbsYkJkMM2VEREQeyn6cGMpdzJ07V3LkyKGV+sl8mClzA6zmT0REzrpw4YKUL1/eNpgfmjdvzoDMxBiUmRyr+RMRkbPfG1gWqUSJEvLbb79Jjx49dBuZH4Myk2M1fyIiiqx79+5Jw4YNpVOnThIYGKhLJmEcGWdWugcGZW6E1fyJiCg8W7dulSJFimgQhuKvY8eOlW3btomfn5/RTaNI4kB/N8J4jIiIHDlw4IDUrFnTNqAf61YWL17c6GaRkxiUmRyHARAR0euUK1dO6tWrJ5kyZdIMWaJEiYxuEkUBgzIT4yB/IiIK7/th9uzZ0rRpU0mePLkObVm5cqUuKk7ui2PKTIyD/ImIKKxbt25J7dq1dTB/t27dbNsZkLk/BmVugoP8iYho/fr1Oph/8+bNEj9+fO22ZLkLz8Gw2k0wHiMi8l4ob9G3b1+ZPn26XkZgtnTpUilYsKDRTaNoxKCMiIjI5JX569evL+fPn9fLvXv3llGjRmmmjDwLgzIiIiITS506tTx8+FB8fX1lwYIFUr16daObRC7CoMzEOEyAiMg7/fvvv5IqVSodS5wmTRpZt26dZM2aVc+T5+JAf5NiOQwiIu/k7+8vuXPn1gKwViVLlmRA5gUYlJlU4AuWwyAi8iYBAQHSvn17rT12//59mT9/PmdWehnDg7KpU6dKtmzZJEGCBFK2bFk5dOhQhNefOHGi5M2bVxImTCiZM2eWXr16ybNnz8STs2Qsh0FE5NkOHjyoyyLNmzdPj/cDBw6UTZs28djvZQwNypYvX66zSIYOHSpHjx6VokWL6tpdd+7ccXh9TP/t37+/Xv/cuXMyZ84cvQ+8eT25aGyieMySERF5oqCgIBk+fLhUqlRJLl26JFmyZJFdu3bJyJEjdVFx8i6GBmXjx4+Xjh07Srt27aRAgQIyY8YMXa9r7ty5Dq+/f/9+qVixorRo0UKzazVq1JDmzZu/NrvmzpglIyLyXIcPH9ZEQ3BwsHz44Ydy4sQJqVy5stHNIm8Lyl68eCFHjhyRatWq/V9jYsfWy1jt3pEKFSrobaxB2OXLl2Xjxo263ER4nj9/Lo8ePQp1cieMx4iIPBcq8g8bNkwWLVqkvUEpUqQwuknkjUHZvXv39JdB+vTpQ23HZazr5QgyZNY0L9K6OXPmlLfffjvC7svRo0frYq3WE8ahERERGeHBgwfSoUMH7aq0QqasVatW7BUh4wf6OwP97KhiPG3aNB2DtmrVKtmwYYOMGDEi3NsMGDBAi+5ZT9euXYvRNhMREcGePXt07DSG6Hz00UecWUnmKR6Leitx4sSR27dvh9qOyxkyZHB4m8GDB0vr1q3l448/1suFCxeWJ0+eSKdOnWTQoEHa/RkWlqHgUhRERGSUly9fahclem4QiKGXZ9y4ccyMkXkyZfHixdNieNu3b7dtCwkJ0cvly5cPd0HWsIEXAjvgLw4iIjKbixcv6nho9PLgewoT244dO6YloIhMtcwSymG0bdtWSpUqJWXKlNEaZMh84U0Lbdq0kUyZMumvC6hTp47O2EQtF7yh//zzT82eYbs1OCMiIjKD3377TapWraoJhZQpU8rMmTOlcePGRjeLTMzQoKxZs2Zy9+5dGTJkiA7uL1asmGzevNk2+P/q1auhMmNffvmlpnvx/40bNyRt2rQakKGeCxERkZkggYBi5wjIsJC4n5+f0U0ik4tl8bJ+P5TEwCxMDPpPliyZmFHgiyApMGSLnj87vKYkisd144mI3MGvv/6qPT/Wwq9IPKROndrhmGfyHo8iGXvwXUJERPSGUBOzT58+WrLJviIAenQYkFFkMQVDRET0Bs6cOaN1NE+ePKmXkQ1BJxRnV5KzGL6bkHd1KBMRuScEXpMnT9bJagjIkBVbt26dTJo0iQEZRQkzZSb8kDeZ4XiZKSIiMgfU1ESlgE2bNunlWrVqybx5815ZpYbIGcyUmczTl8Fy9ub/1ucs4JtMEvqw1AcRkRmXS9q9e7ckSJBAs2VYXYYBGb0pZspMzL9zeabAiYhMAus1W2tiotTFwoULJV++fFKwYEGjm0YegpkyE2M8RkRkDlhvGetWYv1Kq0aNGjEgo2jFoIyIiCgcWP5v7NixUq5cOZ1l2b9/fy7rRy7D7ksiIiIHrl+/rksB7tixQy83aNBAZs2axWEl5DLMlJkMf4ARERnP399fihQpogFZokSJZPbs2fLTTz9pdX4iV2GmzERYDoOIyHiYVdm0aVM9X7p0aVmyZInkzp3b6GaRF2BQZiIsh0FEZLzKlStL48aNdYbl0KFDbetYErkagzKTYjkMIqKYERQUpFX427dvLylTptRj7/Lly7lmJcU4vuNMivEYEZHrXb58WapUqSJ9+/aVLl262GZWMiAjI/BdR0REXgfB16JFi6RYsWKyf/9+SZYsmdSpU4c9FGQodl8SEZHXLZGErNiyZcv0csWKFWXx4sWSLVs2o5tGXo6ZMhNhOQwiItc6ceKElrpAQIYlk0aMGCG7du1iQEamwEyZSbAcBhGR62XOnFmr9OfMmVNLXZQtW9boJhHZMCgzCZbDICJyjRs3bkjGjBl1vFiqVKlk06ZNkj17dkmSJInRTSMKhd2XJsRyGERE0dMDgWWR8uTJIwsXLrRtL1y4MAMyMiUGZSbEeIyI6M3cu3dP16rs1KmTBAYGypo1a7iQOJkegzIiIvIoW7du1WzYzz//rNX4x40bp+tWsgeCzI5jyoiIyCM8e/ZMBgwYIBMnTtTL+fPn18H8xYsXN7ppRJHCTJlJMKtORPRmjh49qsslQdeuXeXw4cMMyMitMFNmAiyHQUT05ipUqCCjRo2SQoUKyQcffGB0c4icxkyZCbAcBhGR827duiWNGzeWP/74w7atf//+DMjIbTFTZjIsh0FE9Hrr1q2T9u3b6yxLnFCVn8jdMVNmMozHiIjCh/IWWLeybt26GoxhyaSpU6ca3SyiaMGgjIiI3GYgf8mSJWXGjBl6uXfv3nLo0CEpWLCg0U0jihbsviQiItPbs2ePVKtWTV6+fCm+vr6yYMECqV69utHNIopWDMqIiMj0ypUrJ0WLFtUFxbF0UurUqY1uElG0Y1BGRESmtHnzZnn33Xe1Kn+8ePFk27Ztkjx5ck6GIo/FMWVERGQqAQEB0q5dO6lVq5YMGzbMtj1FihQMyMijMVNGRESmcfDgQWnZsqVcvnxZA7A4cVi3kbwHgzIiIjJcUFCQVuMfPny4BAcHS5YsWWTx4sXy1ltvGd00ohjDoIyIiAz1119/aXZs//79erlFixZaewzdlUTehEEZEREZCmUuTpw4IcmSJZNp06ZpgEbkjRiUERFRjHvx4oXOqITcuXPLsmXLdCHxbNmyGd00Ivecffns2bPoawkREXlNIdi8efOGWq8Si4gzICNv53RQFhISIiNGjJBMmTJJkiRJdIYMDB48WObMmeOKNhIRkYdkxwYOHChvv/22jiPDoH4ieoOg7Ouvv5b58+fLt99+a0s9A9LOs2fPdvbuiIjIC1y8eFEqVqwoo0ePFovFIu3bt5e1a9ca3Swi9w7KFi5cKDNnztSBmPb1Y7D8xfnz56O7fV7BYjG6BUREroEADMsiFS9eXA4fPiwpU6aUlStXas8KeluI6A0G+t+4cUNy5crlsFsTM2jI+QNWkxkHjG4GEZFLbN++XTp16qTnq1atqguJ+/n5Gd0sIs8IygoUKCB79+6VrFmzhtqOXz74JUTOefoyWM7efKTnC/gmk4Q+rF5NRJ4Da1eiZwXfD7169ZLYsbm6H1G0BWVDhgyRtm3basYM2bFVq1bJhQsXtFtz/fr1zt4d2fHvXJ7ruhGRW8OsfIwb69mzp6RKlUqPaYsWLeKxjSgSnP7JUq9ePVm3bp388ssvkjhxYg3Szp07p9uqV6/u7N2RHR6ziMidnTlzRsqWLauzKjt37mzbzoCMyIXFY7EW2bZt26JyUyIi8sCxsVOmTJHPP/9cnj9/LmnTppU2bdoY3Swiz8+U5ciRQ/79999Xtj948ED/RkRE3uPWrVtSu3Zt6dGjhwZktWrVklOnTmkxWCJycaYMBf+Cg4Nf2Y4PI8aZERGRdzh06JC8//77cu/ePUmQIIGMHTtWunXrxu5KIlcHZfZF/rZs2SLJkye3XUaQhmnPXCKDiMh7YM1KBGNFihSRpUuXSsGCBY1uEpF3BGX169fX//ELCLMv7fn4+GhA9t1330V/C4mIyDQuXbqkQ1XwXYBCsJj0heN//PjxjW4akfeMKUP5C5yyZMkid+7csV3GCV2XKIvBMQTOYzV/InIHONZjeb38+fPLvHnzbNuxsDgDMiKDBvpfuXJF0qRJE00P791YzZ+I3MH169elWrVq8sUXX+jKLbt27TK6SUQeKUolMZ48eSK7d++Wq1evyosXL0L9DTNwKHJYzZ+IzM7f318++eQTuX//viRKlEi+//57XUyciEwQlB07dkynPwcGBmpwhorNmHmDD2u6dOkYlEURq/kTkZkEBATo8Xz+/Pl6uVSpUrJkyRLJkyeP0U0j8lhOd19i7bI6deror6aECRPKwYMH5e+//5aSJUvKuHHjXNNKL8B4jIjM5OTJk7p4OH4sDho0SPbv38+AjMhsmbLjx4/LDz/8oIvKxokTRwf5YyYOBoBiVmbDhg1d01IiIooxFStW1Bn1+MFduXJlo5tD5BWczpSh/AUCMkB3JcaVAeqWXbt2LfpbSERELodJXDVr1pSLFy+G6hlhQEZk4qCsePHi8vvvv+v5KlWq6ILkGGfw2WefSaFChVzRRiIicuEs8EWLFknRokVl69at0qVLF6ObROS1nA7KRo0aJb6+vnp+5MiRWjwQH+K7d+9qt6azpk6dqoUHURW6bNmyumxHRLDGJpbxQBtQGwdjHDZu3Oj04xIReTscT1u0aKGLh2NgP7osZ8+ebXSziLyW02PKMAPHCt2XmzdvjvKDL1++XHr37i0zZszQgGzixImaPkchWtx3WCi/Ub16df3bypUrJVOmTDrJIEWKFFFuAxGRN9qzZ4+0bt1ah6BgfPDQoUNlwIABEjdulColEZERmbLwHD161OmK/uPHj5eOHTtKu3btpECBAhqcobTG3LlzHV4f2//77z9Zs2aN/qJDhg1dqEi7ExFR5GBppLffflsDspw5c8qvv/4qgwcPZkBG5E5BGRYi79u3rwwcOFAuX76s286fP6/rYpYuXVqX4YgsZL2OHDmiVaJtjYkdWy8fOHAg3EXRy5cvr92X6dOn1zFs6E7FgujhwezQR48ehToREXkz/JjFMRtFYFF7Ej0VRORGQdmcOXOkVq1aWkjwm2++kXLlysnixYs1SMqQIYOcPn3aqbFdKDiLYArBlT1cvnXrlsPbIBBEtyVuh8fCLztM2f7666/DfZzRo0frzFDrKXPmzJFuIxGRpwzmX7FihW0FFsyi37lzpx7XkyZNanTziMjZoGzSpEkajCGYwocb/0+bNk1OnTql3Y5YpNbVkInDeLKZM2dq7ZxmzZppUUM8fngwRuLhw4e2E8t2EJE3wbEa9SNxvMRseSsMFSEic4n0AIJLly5JkyZN9Dw+4Bh7MHbsWPHz84vSA2NRcwwuvX37dqjtuIzMmyOYcYlfeLidFYJBZNbwCzBevHiv3AYzNHEiIvI227Zt06LeN2/e1GNn2rRpjW4SEUVHpuzp06e2X1ZYdgOBjrU0RlQggEK2a/v27aEyYbiMLlFHMLj/zz//DDV2DYUO0Q5HAZnZWSxGt4CIPNGzZ890ZnuNGjU0IMuXL5/89ttv0qdPH6ObRkQRcGqqDerXJEmSRM8HBQXp+DJkvOw5syA5Dhr4FYcyG2XKlNGSGFjkHLMxAbVzUPYC48IA9dCmTJkiPXv2lO7du8sff/yhA/3dcRF0jPFoMsPxhAYioqjC5Ct0VWLtSujatav2arC7ksiDgrIsWbLIrFmzbJfRxYgq0PaQQXMmQMKBA0VnMc4BXZDFihXTumfWwf+Yrm1d0gkwSB8zQLH0R5EiRTRgQ4D2xRdfiLt5+jJYzt7830zQAr7JJKHP/3XJEhFFFbopMSkKXZUoI+RsqSIiMk4sC1I2XgQlMTALE4P+kyVLZlg7Al8ESYEhW/T8ma9qSuL4rA9ERFETGBgYKhOGsWT44Rp2djsRmTv2iLbisRR1sWIZ3QIiclfr16+XHDlyyI4dO2zbsPIJAzIi98OgjIjITbNjGC9Wp04dnbWOmo1E5N4YlBERuRlU4cfs9enTp9smTa1atcroZhHRG2JQRkTkJlAOCDMpsSwSZlmiHNDWrVs1S8Z6jETuj0EZEZGbwOz0fv36ycuXL6VBgwa6ogrGjxGRFwdlqO7/5ZdfSvPmzeXOnTu6bdOmTXLmzJnobh8REf1/WH8Yi4ijPNFPP/0kqVOnNrpJRGRkULZ7924pXLiwVofGGIbHjx/r9hMnTsjQoUOjs21ERF4tICBAx4v9+++/tlqQWET8448/1vNE5OVBWf/+/eXrr7/WOjj2SxtVrVpVDh48GN3tIyLySjieFi9eXCZMmCCdO3c2ujlEZMagDGMYMJYhrHTp0sm9e/eiq10ez7tK9hJRZGEJuxEjRkilSpV0qAhWU8GyckTk+ZwOylKkSKEL3Dqaoo1lj+j1uO4lETly5coVefvtt3XpueDgYB23i6EhlStXNrppRGTGoOzDDz/UtSaxViXGNGCK9q+//ip9+/bVBcTp9bjuJRGFtXfvXilatKgeT7EMy+LFi2Xp0qX6Q5iIvIPTQdmoUaMkX758ujg4BvkXKFBAf8VVqFBBZ2SSc/w7l+eAXSLSCVQpU6aUihUryvHjx6Vly5ZGN4mIYpjTq2BjcD+mYw8ePFhOnz6tgRkGo+bOnds1LfRwjMeIvBfG6BYqVEh/mCEjtmvXLv3BGzeu04dmIvLGTNm+ffv0fww+rV27tjRt2pQBGRGRE1D8ddCgQdpdOXv2bNv27NmzMyAj8mJOB2UofYEDx8CBA+Xs2bOuaRURkYe6ePGiDvfAUBBM+kG2jIgoSkHZP//8I3369NEiski7FytWTNdiu379Ol/RSGI5DCLvgwAMQz8w3OPw4cM6fmzlypXy/fffG900InLXoCxNmjTy6aef6gwh1NBp0qSJLFiwQLJly6ZZNIoYy2EQeR/UcGzYsKF06tRJAgMD9Vh58uRJadSokdFNIyJPWZAc3Zio8D9mzBidOYTsGUWM5TCIvM+FCxdk7dq14uPjoz0LWBHFz8/P6GYRkclEeUQpMmVLlizR9PuzZ8+kXr16Mnr06OhtnYdjOQwiz86KWz/fKHMxefJkKV++vHZfEhFFS6ZswIABmiFD+v3q1asyadIkLSS7aNEiee+995y9O6/GeIzIM6FcEAbznz9/3rata9euDMiIKHozZXv27JHPP/9cS2FgfBkREf1fdmzKlCl6jHz+/Ll89tlnsnnzZqObRUSeGpSh25KIiEJDj0G7du1sQRjqOM6dO9foZhGRpwVlGKBaq1YtHaSK8xGpW7dudLWNiMgtrFu3Ttq3b6+zLBMkSCDjxo3T7kqOGSWiaA/K6tevr78C06VLp+fDgwNQcHCwUw0gInJn69evt/0YLVKkiC4iXrBgQaObRUSeGpSFhIQ4PE9E5O0wwQmD+jGzcuTIkRI/fnyjm0RE3jL7cuHChTqANawXL17o34iIPBl+mGK9SutxEGtV7ty5U7ssGZARUYwGZRjI+vDhw1e2BwQE6N+IiDzVtWvXpFq1atKxY0f58ssvbdvjxYtnaLuIyEuDMvuCiPaw9mXy5Mmjq11ERKbi7++vY8aQFUuUKJHky5fP6CYRkbeWxEDRQwRjOL377ruasrfC4P4rV66weCwReRz0AvTo0UPmz5+vl0uXLq2rmeTOndvophGRtwZl1lmXx48fl5o1a0qSJElCpe6xIDkX1yUiT4LjHY5rly9f1h+kAwcOlKFDh2p5ICIiw4IyHIgAwVezZs20Fg8RkSfDkIy7d+9KlixZZPHixfLWW28Z3SQi8mBOV/Rv27ata1pCRGQCDx48kBQpUuh5rPOLOmQYS2bdRkRk6ED/VKlSaaVqSJkypV4O70RE5I4wiWnRokXaG7Bt2zbb9sqVKzMgIyLzZMomTJggSZMmtZ3n0iFE5GnZsS5dusiyZcv08syZM6V69epGN4uIvExcZ7ssP/roI1e2h4goRu3evVtat26tNcjixIkjw4YNk/79+xvdLCLyQk7XKTt69KicOnXKdvnnn3/WmZmYlYSq/kRE7gDHKxy33nnnHQ3IcubMKb/++qsWhbUv+UNEZNqg7JNPPpGLFy/qeUwTx0xMFFJEYcV+/fq5oo1ERNFuy5YtMnr0aB1L1r59ezl27JiULVvW6GYRkRdzOihDQFasWDE9j0CsSpUqsnTpUi2s+NNPP7mijURE0a5OnTrSrVs3PY7NmTPHNm6WiMitllnCgrzwyy+/SO3atfV85syZbTM0iYjMBsenjz/+WOuOWU2ZMkUaN25saLuIiKycHjhRqlQp+frrr3VRXgyQnT59um7HMkvp06d39u6IiFxu69atOknp5s2b8vDhQ82OERG5faZs4sSJOtj/008/lUGDBkmuXLl0+8qVK6VChQquaCMRUZQ8e/ZMevXqpUvDISDLnz+/Du4nIvKITBkqW9vPvrQaO3asTicnIjKD06dPS4sWLWzHq65du+pxChOTiIjMKMrzvo8cOSLnzp3T8wUKFJASJUpEZ7uIiKIMFfkxkP/58+eSNm1amTt3rnzwwQdGN4uIKHqDsjt37mgZDIwnsy49gmrYqPWDatg4ABIRGQmlLXx9ffUHIwIyjnclIo8cU9a9e3d5/PixnDlzRv777z89oZvg0aNH0qNHD9e0kojoNQ4cOKCzwyFZsmRaCBaLiTMgIyKPDco2b94s06ZN0wGzVvg1OnXqVNm0aVN0t4+IKEKBgYE6XgwTjX744Qfb9owZM3KdXiLy7O5L1Cjz8fF5ZTu2WeuXERHFBMwEb9mypZw/f14vX79+3egmERHFXKasatWq0rNnT/nnn39s227cuKHTzt99992ot4SIKJLwAxAzKcuVK6cBGbJiGNyPGopERF4TlKECNsaPZcuWTRfwxSl79uy6bfLkya5pJRHR/4dsWPXq1XWt3ZcvX0qDBg3k5MmTWtCaiMirui+xnBK6DLZv324riYHxZTwgRs7/H4dMRFF07do1nf2NemPff/+9LibOsWNE5HVB2fLly2Xt2rXy4sUL7arETEyKPMwMazLjgNHNIHLL7srYsf+X2C9fvrzMmjVLKlWqJLlz5za6aUREMd99iTUumzdvLocPH5Y//vhDunXrJp9//nn0tcQLPH0ZLGdvPtLzBXyTSUIfroBA9DoHDx6UokWLytmzZ23b2rVrx4CMiLw3KMNYsqFDh8qFCxfk+PHjsmDBAi2NQVHj37k8u1yIIhAUFCTDhw/XjBhqIfbv39/oJhERmSMou3z5srRt29Z2GWvK4aCJRX7JeYzHiMJ35coVqVKliv4QDA4O1uPNwoULjW4WEZE5gjKsIZc4ceL/u2Hs2BIvXjx5+vSpq9pGRF447nLRokXaXbl//36tzL948WJZsmSJbVk3IiJP5dRA/8GDB+uMJysM+B85cqQkT57ctm38+PHR20Ii8hqrVq2SNm3a6PmKFStqQIbyO0RE3iDSQVnlypV1PJk9LGuCbk0rjpEiojdRr1497bZEiR2MIYsb1+mqPUREbivSR7xdu3a5tiVE5HWQbceEoS5dukj8+PE1CEMNxDhxODOZiLwPf4YSkSGQece6lUeOHNGCsN99951uZ0BGRN7K6WWWXGHq1Kk6biRBggRStmxZOXToUKRut2zZMu0yrV+/vsvbSETRN5gfxV9LlCihAVnKlCl1KAQRkbczPCjDKgG9e/fWqe9YvgmzrmrWrCl37tyJ8HZ//fWX9O3bV956660YaysRvZl79+5Jw4YNpVOnThIYGChVq1bVdSsbNWpkdNOIiAxneFCG2ZodO3bUCt0FChSQGTNm6AzPuXPnhnsb1C1Ct8dXX30lOXLkiNH2ElHUHDhwQIoUKSJr1qwRHx8fGTt2rGzbtk38/PyMbhoRkSnENnqQL7ov7BczR/0zXMYBPDyo8p0uXTrp0KFDpOqrPXr0KNSJiGJexowZ5cmTJ5I/f3757bffNNNtXc+SiIiiGJTt3btXWrVqpQsD37hxQ7eh4OO+ffuc7spA1it9+vShtuPyrVu3HN4GjzFnzhwdkxIZo0eP1jpq1lPmzJmdaiMRRZ39MISsWbPK1q1bdf3c4sWLG9ouIiKPCMp++uknHfOVMGFCOXbsmGai4OHDhzJq1ChxpYCAAGndurUGZGnSpInUbQYMGKBts54wy4uIXD+Yf/LkyTqBZ8uWLbbtmMhjX4CaiIjeICj7+uuvddwXAiOMC7FC9W0M1HcGAitMf799+3ao7bicIUOGV65/6dIlHeBfp04drWeEE9bDW7t2rZ7H38NC7SMs1WJ/IiLXQZa7du3a0qNHD12GDbOkiYjIBUEZaguhun9Y6Bp88OCBU/eFtTNLliypxSKtQkJC9DK6RsPKly+fnDp1So4fP2471a1bV9555x09z65JImOtW7dOChcuLJs3b9YSN8iWRTRph4iI3qB4LDJYf/755yvr0WGsV1RmQqIcRtu2baVUqVJSpkwZmThxog4GxmxMwDp4mTJl0rFhOMgXKlQo1O2tixSH3U5EMQflLTBwf/r06XoZsyyXLl0qBQsWNLppRESeG5ShfEXPnj311y8Kt/7zzz86UxIHZCxY7qxmzZrJ3bt3ZciQIdrtUaxYMf2VbR38f/XqVc7QIjI5lLawBmT4oYXxpRg6QEREkRfLghG5TsDVccBF5gq/jgEHXwRlI0aMELNDSQx0tWLQf0yPLwt8ESQFhvxv0PPZ4TUlUTyuckWeA8cATAKqXr260U0hInLL2MPpoMy+xhi6MR8/fqxFX5MkSSLugEEZ0Zu7fv269OnTR8eMoWYgERG9eewR5agAg/QRjBGRd/H395dPPvlE7t+/b1sqjYiI3pzTQRlmOmIsWXh27Njxpm0iIhNCnUCUuZg/f75exuQcdxiyQETksUEZBuLbe/nypZajOH36tM6iJCLPc/DgQV1v9vLly/qjDEWZhw0bFqpWIRERxXBQNmHCBIfbcYDG+DIi8rzaYw0aNNAl0bJkyaJLqjmqVUhERG8m2mpNYC1MFokk8jxVqlTRdSubN28uJ06cYEBGROQi0Tb9D7XKUNyViNwbJmT/8ssvUq1aNe2qxEyhQ4cOSerUqY1uGhGRR3M6KGvYsOErB/CbN2/K4cOHo1Q8lojMA0uldenSRdernDJlinTr1k23MyAjIjJhUIY6G/ZQbT9v3rwyfPhwqVGjRnS2jYhi0J49e6R169a6ikacOHF0uTMiIjJpUIaBvliTEgsOp0yZ0nWtIqIYgxnUmKiDVTqQ+c6ZM6csWbJEypYta3TTiIi8ilMD/fHrGdkwdHEQkfv7448/pEKFCrp0GgKy9u3by7FjxxiQERG5w+zLQoUKaa0iInJ///33nwZhyHyvXLlS5syZI0mTJjW6WUREXsnpoOzrr7/WhYfXr1+vA/yxnpP9icIXtVVGiaJXUFCQ7TwyYgsXLpSTJ09Ko0aNDG0XEZG3i3RQhoH8GPhbu3ZtrVVUt25d8fPz01/YOKVIkYLjzCKArqEmMw4Y3Qzyctu2bdOJOViBw6pFixb6WSYiIjcZ6P/VV19J586dZefOna5tkYd6+jJYzt78XyaxgG8ySegTx+gmkRd59uyZDBw40LYiB35krVixwuhmERFRVIIyZHqs1b3pzfh3Lh/hou5E0enMmTOaDUMXJXTt2lXGjh1rdLOIiOhNxpQxkIgefBkpJuCH1OTJk6VUqVIakKVNm1bXsZw6daokSpTI6OYREdGb1CnLkyfPawMzzOYiIuOhKn+PHj30fK1atWTevHmSPn16o5tFRETREZRhXFnYiv5EZE5NmzaV+fPnS506dXS5JGa6iYg8KCj78MMPJV26dK5rDRFFWWBgoHz33Xfy+eefS4IECbTY8+bNmxmMERF5WlDGAzuReaEALAbznz9/Xv7991+ZOHGibufnlojIAwf6W2dfEpF5hISE6ExKFIFFQObr6yvvv/++0c0iIiJXZspw8Cci87h+/bq0bdtWduzYoZcbNGggs2bNktSpUxvdNCIicvWYMiIyBwRijRs3lvv372t5i0mTJkmHDh3YXUlE5MYYlBG5oVy5cmn2GjXIlixZouVqiIjIvTEoI3ITV69elSxZsuh5/L97924pUKCA+Pj4GN00IiKK6Yr+RBTzgoKCdK3KnDlzysaNG23bixYtyoCMiMiDMCgjMrErV67oerNDhw7V4GzLli1GN4mIiFyEQRmRCaEEzeLFizUbtn//fkmWLJlexoB+IiLyTBxTRmQyDx48kC5duujalVCxYkUNyLJly2Z004iIyIWYKSMymZ07d2pAhmWSRowYIbt27WJARkTkBZgpIzIZFIH98ssv5YMPPtBK/URE5B2YKYshXKWKwnPhwgWpXbu23L5927YNGTIGZERE3oVBWQwN2m4y44DRzSATvi+wLFKJEiVk06ZN8tlnnxndJCIiMhC7L2PA05fBcvbmIz1fwDeZJPSJY3STyGD37t2Tjh07ypo1a/Ry1apVdWFxIiLyXsyUxTD/zuW5PqGX27ZtmxQpUkQDMhR/HTdunG7z8/MzumlERGQgZspiGOMx77ZixQpp1qyZns+fP78sXbpUihUrZnSziIjIBBiUEcUgDOjHYuI1atTQ7spEiRIZ3SQiIjIJBmVELh7Mv3r1aqlfv77Ejh1bkiRJIkePHpWkSZMa3TQiIjIZjikjcpFbt25pZqxRo0YyZcoU23YGZERE5AiDMiIXWLdunRQuXFg2b94sCRIkkPjx4xvdJCIiMjl2XxJFo8DAQOnTp4/MmDFDL2OWJQbzFyxY0OimERGRyTFTRhRNTpw4oYVgrQEZgrNDhw4xICMiokhhpowomrx8+VIuXbokvr6+smDBAqlevbrRTSIiIjfCoIzoDTx79kzHjEGpUqW0DlnlypUlderURjeNiIjcDLsviaLI399fsmfPLidPnrRta9CgAQMyIiKKEgZlRE4KCAiQdu3aSdOmTbXsBZZJIiIielMMyoiccPDgQV0Waf78+bqG6aBBg2TOnDlGN4uIiDwAx5QRRUJQUJCMGjVKhg8fLsHBwZIlSxZZvHixvPXWW0Y3jYiIPAQzZUSRsGTJEhk6dKgGZC1atNDyFwzIiIgoOjFTRhQJrVq10jUsmzRpIi1btjS6OURE5IGYKSNy4MGDB9KvXz+t0A9x4sSRNWvWMCAjIiKXYaaMKIw9e/ZI69at5erVq/L06VOZPHmy0U0iIiIvwEwZ0f/34sULGThwoLz99tsakOXMmVO7LYmIiGICM2VEInLhwgXtmjxy5Ihe7tChg0ycOFGSJElidNOIiMhLMCgjr7dhwwYtBIvxYylTppRZs2ZJo0aNjG4WERF5GQZl5PWKFi0q8ePHl3LlyulC4n5+fkY3iYiIvBCDMvJK58+fl3z58ul5BGEHDhyQ3LlzS+zYHGZJRETG4DcQeZVnz55Jr169pECBArJu3Trb9rx58zIgIyIiQ5niW2jq1KmSLVs2SZAggZQtW1YOHToU7nUx3geV1DH2B6dq1apFeH0iq9OnT0uZMmV0AL/FYuH7hoiITMXwoGz58uXSu3dvXcLm6NGjOr6nZs2acufOHYfX37VrlzRv3lx27typXU6ZM2eWGjVqyI0bN2K87eQeEICh1lipUqXk1KlTkjZtWs2SjRgxwuimERER2cSy4BvLQMiMlS5dWqZMmaKXQ0JCNNDq3r279O/f/7W3x1qEyJjh9m3atHnt9R89eiTJkyeXhw8fSrJkySQmBL4IkgJDtuj5s8NrSqJ4HMoXU27duiXt2rWTzZs36+VatWrJvHnzJH369EY3jYiIvMSjSMYesY0u1om6UOiCtDUodmy9jCxYZKCMwcuXLyVVqlQO//78+XN9MexP5D3wPkJAhq5xZMtQ/oIBGRERmZGhQdm9e/c00xX2SxKXkeGIjC+++EIyZswYKrCzN3r0aI1OrSdk4ch7NGjQQEaOHCmHDx+WTz/9VGLFimV0k4iIiMw5puxNjBkzRpYtWyarV6/WTIgjAwYM0HSh9XTt2rUYbyfFHIxLrFy5sty8edO2DUsnFSxY0NB2ERERmTooS5MmjcSJE0du374dajsuZ8iQIcLbjhs3ToOyrVu3SpEiRcK9HoqCov/W/hTTjB215x0wFvHbb7/VArB79+7VDCoREZE7MTQoixcvnpQsWVK2b98e6ssVl8uXLx/u7fDli5lzGCuEGXVmhnkUTWZEbnwcRQ2yn+i+RiCG8YXospwwYYLRzSIiInKK4dMAUQ6jbdu2GlxZa0g9efJEZ8wBZlRmypRJx4bBN998I0OGDJGlS5dqbTPr2DMsHG3GxaOfvgyWszf/N7mggG8ySegTx+gmeRR/f3/55JNP5P79+5IoUSL5/vvvpX379hw7RkREbsfwoKxZs2Zy9+5dDbQQYBUrVkwzYNbB/1evXg1VaX369Ok6a7Nx48ah7gd1zoYNGyZm5t+5PIOFaIR1Kj/66CM9j7IqS5Ys0aWSiIiI3JHhdcpiWkzXKWONMtdBRhXBWMOGDTUo9/HxMbpJREREUY49GCGQ2wgKCtJu61atWmn2NHHixDrbMryZt0RERO7ErUtikPe4cuWKVKlSRccfTpo0ybadARkREXkKBmVkauhdX7Roka6Jun//fk37vq5cChERkTti96WLedeIvej14MED6dKlixYIhooVK8rixYt11i0REZGnYabMhVij7M3WrERRYARkKDCMunS7du1iQEZERB6LmTIXYo2yqMNKDCiRkjNnTi11UbZsWaObRERE5FIMymIIa5S9XkBAgCRNmlTPlyhRQn7++WepVKmSbRsREZEnY/dlDGE8FnE376xZsyRr1qxy/Phx2/ZatWoxICMiIq/BoIwMde/ePS3+2qlTJ10qacaMGUY3iYiIyBAMysgwW7du1cH8a9as0Wr8Y8eOlWnTphndLCIiIkNwTBnFuGfPnsnAgQNlwoQJejlfvnxaqb948eJGN42IiMgwzJS5EGuUOYbZlNaArGvXrnLkyBEGZERE5PWYKXMR1igLX7t27eSXX36Rli1bygcffGB0c4iIiEyBmTIXYY2y/4N6Y8iIBQYG6mUsJv7jjz8yICMiIrLDTFkM8OYaZevXr5f27dvL3bt3NRibMmWK0U0iIiIyJWbKYoA3xmPIiiE7VqdOHQ3IMMsS61gSERGRYwzKKNodO3ZMSpYsKdOnT9fLvXv3lkOHDknBggWNbhoREZFpsfuSotXKlSulRYsW8vLlS/H19ZUFCxZI9erVjW4WERGR6TEoo2hVoUIFXRqpSpUqunRS6tSpjW4SERGRW2BQRm/s6NGjuoA4ZMyYUS9nyZLFayc3EBERRQXHlLmINxSODQgI0JmVGD/2888/27ZjYXEGZERERM5hpswFvKFw7MGDB6VVq1Zy6dIlDcAuXLhgdJOIiIjcGjNlLuDJhWODgoJk+PDhUqlSJQ3I0E25e/du6devn9FNIyIicmvMlLmYJxWOvXLlimbH9u/fr5ebN28u06ZNkxQpUhjdNCIiIrfHoMzFPCQeUydPntSALFmyZBqMYe1KIiIiih4Myui14+Osmb569erJ+PHjpX79+pI9e3ajm0ZERORROKaMwrVnzx6dWXnjxg3btl69ejEgIyIicgEGZfQKVOMfNGiQvP3227pk0pAhQ4xuEhERkcdj9yWFcvHiRR0rdvjwYb2MOmQTJ040ullEREQej5kyso0dw7JIxYsX14AsZcqU4u/vL3PmzNFlk4iIiMi1mClzAXes5j9z5kzp3Lmznq9ataouJO7n52d0s4iIiLwGM2XRzF2r+bdu3VqKFCkiY8eOlW3btjEgIyIiimHMlHlpNf9nz57J3LlzNTsWO3ZsSZQokRw5ckTixuVbgoiIyAj8BvbCav5nzpyRFi1aaDHYp0+fSp8+fXQ7AzIiIiLjsPvShcwWj6FrdfLkyVp7DAFZ2rRpJW/evEY3i4iIiJgp8x63bt2Sdu3ayebNm/VyrVq1ZN68eZI+fXqjm0ZERETMlHmH7du36yB+BGTx48fXbNmGDRsYkBEREZkIM2VeIHXq1PLgwQMNzJYuXSoFCxY0uklEREQUBoMyD/Xff/9JqlSp9HyxYsVk69atUr58ec2UERERkfmw+9LDhISEaK2xLFmyyNGjR23bsY4lAzIiIiLzYlDmQa5fvy7Vq1eXfv36yZMnT2TJkiVGN4mIiIgiiUGZh8A6lRgztmPHDi0Ei3Usx40bZ3SziIiIKJI4pszNBQQESM+ePbW8BZQqVUozZHny5DG6aUREROQEZsrcHGZTIiDDygEDBw6U/fv3MyAjIiJyQ8yUubmOHTvKb7/9Jh999JFUrlzZ6OYQERFRFDFT5mauXLkibdq00YH8gMXEsbA4AzIiIiL3xkyZm8C6lRgr1rVrVx1Hljx5cq3MT0RERJ6BQZkbQDX+Ll26yLJly/RyxYoVpU+fPkY3i4iIiKIRgzKT27Nnj7Ru3VquXr0qceLEkWHDhkn//v0lblzuOiKi6BAcHCwvX740uhnkxvD9jO9lTLp7E/xmN7FFixZJ27ZttesyZ86c2n1ZtmxZo5tFROQxHj9+rIW3cZwlehOoEerr6yvx4sWL8n0wKDOxatWq6WLidevWlYkTJ0rSpEmNbhIRkUdlyBCQ4cs0bdq0b5zlIO9ksVjkxYsXcvfuXZ2Mlzt3bp2EFxUMyky2Y9FdWaVKFb2MiPvUqVOSIUMGo5tGRORx0GWJ4y4CsoQJExrdHHJjeP/4+PjI33//rQFaggQJonQ/LIlhEvfu3ZOGDRvqwuE//fSTbTsDMiIi12KGjKJDVLNj9pgpM4GtW7dq8debN29qpH379m2jm0REREQxjJkyAz179kx69eolNWvW1IAsf/78Wp0ftciIiIjIuzBTZpDTp09LixYtdMwYIBAbO3asDjglIiIi78NMmUH++usvDcgwwHTdunUydepUBmRERBRpBw4c0PpY77///it/27Vrl46VQ/HxsLJly6Yz+u3t3LlTateurTP+8V1UoEABLVJ+48YNl/YWdevWTR8zSZIk0qhRo9cO38HfMdwnY8aM2s733ntP/vjjj1DfrXjejk7+/v56nfnz54d7nTt37tjuC9/L6MHCIP68efPKwoULxdUYlMXw9GurDz74QGbMmKGBGc4TERE5Y86cOdK9e3edtf/PP/9E+X5++OEHLcGEiWWYaHb27Fn9fnr48KF899134ioYvoOkBIKl3bt363PAhLfwYKZs/fr15fLly/Lzzz/LsWPHJGvWrNp263rQmTNn1uFA9qevvvpKg75atWrpdZo1a/bKdTCMCJUP0qVLp9eZPn26DBgwQAu2nzlzRu8DASTa61IWL/Pw4UNUCNT/XeHJ85eWrF+s1xPOW61du9aSJ08ey7Vr11zyuERE5JynT59azp49q/9DSEiIHreNOOGxnREQEGBJkiSJ5fz585ZmzZpZRo4cGervO3fu1O+6+/fvv3LbrFmzWiZMmKDn8Z0UL148y2effebwcRzdPjo8ePDA4uPjY/H397dtO3funLb5wIEDDm9z4cIF/fvp06dt24KDgy1p06a1zJo1K9zHKlasmKV9+/bh/v3OnTvaloULF9q2lS9f3tK3b99Q1+vdu7elYsWKkX4/RSX2MMWYMqQIMZ7q1q1bUrRoUV1ou0yZMuFeH1H14MGDNU2JIm3ffPONpl3NKDAwUFPA+NUBo0aNkmnTphndLCIiCuPpy2ApMGSLIY99dnhNSRQv8l/JK1askHz58mm3WqtWreSzzz7TzI6z5T3wfYq6Wv369XP49xQpUoR7W2Se9u7dG+7fkcVClsmRI0eOaJ04ZLms8uXLJ1myZNFu2XLlyr1ym+fPn+v/9jXAUIYifvz4sm/fPvn4448dPs7x48c1zggPuiXRFdq4ceNQjxW21hi6MQ8dOqTtRqUEj+y+XL58ufTu3VuGDh0qR48e1aAMaUT7fl17+/fvl+bNm0uHDh00dYlUJk4YOG82x44dlZIlS9oCMgRnEyZMMLpZRETkAV2XCMYA46rQ1YguQGdhPFayZMm0WLmzZs+erQFPeKeNGzeGe1skYbAcUdigL3369Po3R6xBG4LP+/fvazCJpAxWZUAXZHivE8aFVahQIdy24DqYeGdfQBhxCJ4fgjp0mx4+fFgvIyBDXVFXMTxTNn78eOnYsaO0a9dOLyOA2bBhg8ydO1cX3g5r0qRJ+gb8/PPP9fKIESNk27ZtMmXKFFvwYzSLJUQeHVol74xfojsQAxIXLFgQ6hcBERGZS0KfOJqxMuqxI+vChQuasVm9erVexkLYGCeF4AIFyJ2BgCOqxXMzZcokMcnHx0dWrVqlSZlUqVLpJAd8ryJj52jt0qdPn8rSpUu1Zy08yMqdO3dO15q2h9sgOETGDveNYBFrUX/77bfRUiTWlJkyRLmIQu2DFTxZXMYL5Qi2hw1uENGGd32kIB89ehTq5GoBR9bLg13zNSBr0KCBnDx5kgEZEZHJIThBF6IRJ2cCIwRfQUFB+oMfARlOGJiOQfrImAGyX2C9bA8zMpMnT67n8+TJo9cJL9MUEQRDGEAf3qlgwYLh3haTChADhJ0devv27QhXskHvE7JwuB3avHnzZvn3338lR44cr1x35cqVOoSoTZs24d4fsl/FihXT+7WHrBmSQ7g9hkpdvXpVZ61iDWpUTfDIoAwpQMxIRAQa2fQltjtz/dGjR+ubz3rCzAxXS1K0psTzzS3TZvygHxJM9yUiInpTCMYwBgqzIu27Ck+cOKFB2o8//qjXsy6KjcSHPcxcRBCGYAwwjgrdiMgAOeKopEZ0dF8iCELma/v27aEygFevXpXy5cu/9nXA9zmCI3S/omuxXr16DoPXunXrhhtEPX78WMfmIfMWHrTRz89Ps3LLli3TagmuzJQZ3n3pauh7xpg1K2TKXBmYIQV9fnRdCRn5gSSO78M11YiIKNqsX79ex1MhkLBmu6xQ5wuBSOfOnTWjg4HvGMuMTFrhwoXl2rVr8sUXX2iXnHWMFb4PMdb5008/1e9HZJWQEcI4LQR/yHiFVxbjTbov0XY8B3w/oysSmb3u3btrQGY/yB/jyJBcQa+TdWICgiyMLUNJqZ49e+q48ho1aoS6/z///FNLhUQUGGJMO4Jc69g8excvXtQu4rJly+rrjaFWGLuOoUiuZGhQliZNGo0+wxaLiyh9ie3OXB+zMnCK6fQ3ERFRdEPQheEwYQMya1CGjBeGzBQpUkTHYI8ZM0YDsb///lu/J6tXry4jR44MlTDAijLInI0bN06DH4zFQmCGrJB9UiO6IRhE1gntxlCjmjVrvlKdANkz+y5YdFmiTfjex+QEBJGOxoyh6xEZrrDBWtjXEnXRHM0wRS8eglE8PrJl77zzjk40xOviSrFQF0MMhCgU5S9QBgNCQkI0AkbU7migPwYzoo/XvoAbIn68ASMz0B+/BPBmxk629rkTEZH3QUX5K1euSPbs2V8pf0AUne+nyMYehqd0EPFiRkOpUqU0OMPSD6jMa52NiSgYKVKkLwGpSlTdRQSLpSXQx4v+5JkzZxr8TIiIiIiizvCgDJmvu3fvypAhQ3SwPmZBYDaFdTA/Bv3ZD6pDVgxTXL/88ksZOHCgDmZcs2aNFCpUyMBnQUREROTm3Zcxjd2XREQE7L4ks3VfGl7Rn4iIiIgYlBERkZfzsg4jMvH7iEEZERF5JZRkAlSWJ3pTqAwBb7JYueED/YmIiIyAoqqJEiXSyWb4InVlpXby7AxZYGCg3LlzR2ueWYP9qGBQRkREXgkFVFGAFIOzUVyV6E0gIIto3c7IYFBGREReC+s+orQSuzDpTSDT+iYZMisGZURE5NXQbcmSGGQG7EAnIiIiMgEGZUREREQmwKCMiIiIyATiemtxNyx5QERERORq1pjjdQVmvS4oCwgI0P8zZ85sdFOIiIjIy2KQ5MmTh/t3r1uQPCQkRP755x9JmjSp1qhxVUSMoO/atWtc9Nxg3BfmwP1gHtwX5sD94F37wmKxaECWMWPGCIsUe12mDC+Gn59fjDwWdi4/bObAfWEO3A/mwX1hDtwP3rMvkkeQIbPiQH8iIiIiE2BQRkRERGQCDMpcIH78+DJ06FD9n4zFfWEO3A/mwX1hDtwP5hHfRPvC6wb6ExEREZkRM2VEREREJsCgjIiIiMgEGJQRERERmQCDMiIiIiITYFAWRVOnTpVs2bJJggQJpGzZsnLo0KEIr+/v7y/58uXT6xcuXFg2btwYY231dM7si1mzZslbb70lKVOm1FO1atVeu+/INZ8Jq2XLlunqGvXr13d5G72Fs/viwYMH0q1bN/H19dUZaHny5OExyoD9MHHiRMmbN68kTJhQK8z36tVLnj17FmPt9VR79uyROnXqaDV9HGvWrFnz2tvs2rVLSpQooZ+HXLlyyfz582OkrSj9T05atmyZJV68eJa5c+dazpw5Y+nYsaMlRYoUltu3bzu8/q+//mqJEyeO5dtvv7WcPXvW8uWXX1p8fHwsp06divG2e/u+aNGihWXq1KmWY8eOWc6dO2f56KOPLMmTJ7dcv349xtvuzfvB6sqVK5ZMmTJZ3nrrLUu9evVirL2ezNl98fz5c0upUqUstWvXtuzbt0/3ya5duyzHjx+P8bZ7835YsmSJJX78+Po/9sGWLVssvr6+ll69esV42z3Nxo0bLYMGDbKsWrUK1SYsq1evjvD6ly9ftiRKlMjSu3dv/c6ePHmyfodv3rzZ5W1lUBYFZcqUsXTr1s12OTg42JIxY0bL6NGjHV6/adOmlvfffz/UtrJly1o++eQTl7fV0zm7L8IKCgqyJE2a1LJgwQIXttLzRWU/4LWvUKGCZfbs2Za2bdsyKDNoX0yfPt2SI0cOy4sXL2KwlZ7P2f2A61atWjXUNgQFFStWdHlbvYlEIijr16+fpWDBgqG2NWvWzFKzZk0Xt85iYfelk168eCFHjhzRbi/79TRx+cCBAw5vg+3214eaNWuGe31y3b4IKzAwUF6+fCmpUqVyYUs9W1T3w/DhwyVdunTSoUOHGGqp54vKvli7dq2UL19euy/Tp08vhQoVklGjRklwcHAMttyzRGU/VKhQQW9j7eK8fPmydiHXrl07xtpNxn9ne92C5G/q3r17erDCwcseLp8/f97hbW7duuXw+thOMbsvwvriiy90nEHYDyC5dj/s27dP5syZI8ePH4+hVnqHqOwLfPnv2LFDWrZsqUHAn3/+KV27dtUfK6hyTjGzH1q0aKG3q1SpEnqwJCgoSDp37iwDBw6MoVbT676zHz16JE+fPtUxf67CTBl5rTFjxugg89WrV+tAXIoZAQEB0rp1a510kSZNGqOb4/VCQkI0Yzlz5kwpWbKkNGvWTAYNGiQzZswwumleBQPLkaGcNm2aHD16VFatWiUbNmyQESNGGN00ikHMlDkJXyJx4sSR27dvh9qOyxkyZHB4G2x35vrkun1hNW7cOA3KfvnlFylSpIiLW+rZnN0Ply5dkr/++ktnQ9kHBhA3bly5cOGC5MyZMwZa7nmi8pnAjEsfHx+9nVX+/Pk1W4BuuHjx4rm83Z4mKvth8ODB+mPl448/1suYpf/kyRPp1KmTBsno/qSYEd53drJkyVyaJQPuZSfhAIVfk9u3bw/1hYLLGJfhCLbbXx+2bdsW7vXJdfsCvv32W/31uXnzZilVqlQMtdZzObsfUBrm1KlT2nVpPdWtW1feeecdPY9SABRzn4mKFStql6U1MIaLFy9qsMaALOb2A8a3hg28rIEyl6iOWYZ+Z7t8KoGHTnXG1OX58+frdNlOnTrpVOdbt27p31u3bm3p379/qJIYcePGtYwbN07LMAwdOpQlMQzaF2PGjNFp6itXrrTcvHnTdgoICDDwWXjffgiLsy+N2xdXr17VGciffvqp5cKFC5b169db0qVLZ/n6668NfBbetx/wvYD98OOPP2pJhq1bt1py5syps/fpzeD4jjJIOCHsGT9+vJ7/+++/9e/YD9gfYUtifP755/qdjTJKLIlhcqhbkiVLFv2Cx9TngwcP2v5WpUoV/ZKxt2LFCkuePHn0+phqu2HDBgNa7Zmc2RdZs2bVD2XYEw6IFLOfCXsMyozdF/v379cyPQgiUB5j5MiRWrKEYm4/vHz50jJs2DANxBIkSGDJnDmzpWvXrpb79+8b1HrPsXPnTofHfevrj/+xP8LeplixYrrv8JmYN29ejLQ1Fv5xfT6OiIiIiCLCMWVEREREJsCgjIiIiMgEGJQRERERmQCDMiIiIiITYFBGREREZAIMyoiIiIhMgEEZERERkQkwKCMiIiIyAQZlRBRj5s+fLylSpBB3FStWLFmzZk2E1/noo4+kfv36MdYmIvIcDMqIyCkIOhCchD1hUWszBH3W9mBxZz8/P2nXrp3cuXMnWu7/5s2bUqtWLT3/119/6eNgEXV7kyZN0na40rBhw2zPE4tWYxH3Tp06yX///efU/TCAJDKXuEY3gIjcz3vvvSfz5s0LtS1t2rRiBsmSJZMLFy5ISEiInDhxQoOyf/75R7Zs2fLG950hQ4bXXid58uQSEwoWLCi//PKLBAcHy7lz56R9+/by8OFDWb58eYw8PhFFP2bKiMhp8ePH1wDF/oSMzfjx46Vw4cKSOHFizd507dpVHj9+HO79IGh65513JGnSpBpMlSxZUg4fPmz7+759++Stt96ShAkT6v316NFDnjx5EmHbkD1CezJmzKhZLdwGwcvTp081UBs+fLhm0PAcihUrJps3b7bd9sWLF/Lpp5+Kr6+vJEiQQLJmzSqjR4922H2ZPXt2/b948eK6/e23334l+zRz5kxtBx7XXr169TSIsvr555+lRIkS+pg5cuSQr776SoKCgiJ8nnHjxtXnmSlTJqlWrZo0adJEtm3bZvs7grUOHTpoO/H65c2bV7N49tm2BQsW6GNbs267du3Sv127dk2aNm2qXc2pUqXS9iIzSESuxaCMiKINugy///57OXPmjH7h79ixQ/r16xfu9Vu2bKkB0u+//y5HjhyR/v37i4+Pj/7t0qVLmpFr1KiRnDx5UjNACNIQNDkDAQmCIgQ5CEq+++47GTdunN5nzZo1pW7duvLHH3/oddH2tWvXyooVKzTbtmTJEsmWLZvD+z106JD+j4AP3ZqrVq165ToIlP7991/ZuXOnbRu6GBEI4rnD3r17pU2bNtKzZ085e/as/PDDD9r9OXLkyEg/RwRMyATGixfPtg3PGa+tv7+/3u+QIUNk4MCB+tygb9++GnjhNUb7capQoYK8fPlSXxcEymjbr7/+KkmSJNHrIWglIheyEBE5oW3btpY4ceJYEidObDs1btzY4XX9/f0tqVOntl2eN2+eJXny5LbLSZMmtcyfP9/hbTt06GDp1KlTqG179+61xI4d2/L06VOHtwl7/xcvXrTkyZPHUqpUKb2cMWNGy8iRI0PdpnTp0pauXbvq+e7du1uqVq1qCQkJcXj/OGSuXr1az1+5ckUvHzt27JXXp169erbLON++fXvb5R9++EHbERwcrJffffddy6hRo0Ldx6JFiyy+vr6W8AwdOlRfB7z2CRIk0HbgNH78eEtEunXrZmnUqFG4bbU+dt68eUO9Bs+fP7ckTJjQsmXLlgjvn4jeDMeUEZHT0OU4ffp022V0V1qzRujuO3/+vDx69EizU8+ePZPAwEBJlCjRK/fTu3dv+fjjj2XRokW2LricOXPaujaRzUK2ygpxETJAV65ckfz58ztsG8ZVIbOD6+GxK1WqJLNnz9b2YGxZxYoVQ10fl/FY1q7H6tWra1cfMkMffPCB1KhR441eK2TEOnbsKNOmTdMuUzyfDz/8ULOK1ueJbJR9ZgxdjxG9boA2IquH6y1evFgnHHTv3j3UdaZOnSpz586Vq1evavctMl3oso0I2oNJG8iU2cPjIHtJRK7DoIyInIYgLFeuXK90oSGI6dKliwYYGIuE7kaMa0Iw4Ci4wLimFi1ayIYNG2TTpk0ydOhQWbZsmTRo0EDHon3yySc6JiysLFmyhNs2BBNHjx7VoAdjw9B9CQjKXgfjuhDwoS0IMNG9h2Bx5cqVElV16tTRYBLPsXTp0tolOGHCBNvf8Twxhqxhw4av3BZjzMKDrkrrPhgzZoy8//77ej8jRozQbXgd0UWJ7try5cvr6zJ27Fj57bffImwv2oOxffbBsNkmcxB5KgZlRBQtMCYM2SkEAdYskHX8UkTy5Mmjp169eknz5s11VieCMgRIGAsVNvh7HTy2o9tgIgEG3SMrVaVKFdt2XC5Tpkyo6zVr1kxPjRs31owZxoEhyLRnHb+FrFZEEFgh4EKQgwwUMlx4blY4j/Frzj7PsL788kupWrWqBsXW54kxYphsYRU204XnELb9aA/G76VLl05fCyKKORzoT0TRAkEFBolPnjxZLl++rF2SM2bMCPf66E7DoH3M+Pv77781iMCAf2u35BdffCH79+/X66BrDoPxMVPQ2YH+9j7//HP55ptvNOhAIISJBbhvDLIHzB798ccftfv14sWLOkgeMxwdFbxF0IIsHAbt3759W7tNI+rCRKYMXYnWAf5WGIC/cOFCzXJhggTKWyDLhSDLGciGFSlSREaNGqWXc+fOrTNZMQEAz2Xw4MH6+trDJAZ0EeO1uHfvnu4/tC9NmjQ64xJZPWQOsY+Qsbx+/bpTbSIi5zAoI6JoUbRoUQ1qEPQUKlRIM0P25STCQgkNzEzEzENkytBViBIWCE4AAcbu3bs1oEBZDJSeQACDLFBUIbDAOLY+ffpo6Q4EVBiXhQAG0MX37bffSqlSpbSrEV2yGzdutGX+wpakwGxNzJZEmxDEhAcZLGTaEPygu9YeZjquX79etm7dqo9Zrlw57d5EOQ5nIduI8XMoaYGuX2TokPErW7asvtb2WTPAWDdk7vB80TWJwBjdzHv27NEuYtweQTK6oDGmjJkzIteKhdH+Ln4MIiIiInoNZsqIiIiITIBBGREREZEJMCgjIiIiMgEGZUREREQmwKCMiIiIyAQYlBERERGZAIMyIiIiIhNgUEZERERkAgzKiIiIiEyAQRkRERGRCTAoIyIiIhLj/T/HA26buoxLAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.977886542145467\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluation: ROC Curve + AUC\n",
    "# ============================================================\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
    "plt.plot([0,1], [0,1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve â€“ EfficientAD Brain Tumor Detection\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC =\", roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
